{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "super-amount",
   "metadata": {},
   "source": [
    "# Laboratorio no calificado: Recorrido por los metadatos de ML\n",
    "\n",
    "Mantener registros en cada etapa del proyecto es un aspecto importante de los conductos de aprendizaje automático. Especialmente en los modelos de producción que implican muchas iteraciones de conjuntos de datos y reentrenamiento, tener estos registros ayudará a mantener o depurar el sistema desplegado. [ML Metadata](https://www.tensorflow.org/tfx/guide/mlmd) responde a esta necesidad al disponer de una API adaptada específicamente para el seguimiento de los progresos realizados en los proyectos de ML.\n",
    "\n",
    "Como se ha mencionado en los laboratorios anteriores, ya has utilizado ML Metadata cuando has ejecutado tus pipelines TFX. Cada componente registra automáticamente la información en un almacén de metadatos a medida que va pasando por cada etapa. Esto le permitió recuperar información como el nombre de las divisiones de entrenamiento o la ubicación de un esquema inferido. \n",
    "\n",
    "En este cuaderno, se estudiará más detenidamente cómo se pueden utilizar los metadatos ML directamente para registrar y recuperar metadatos independientemente de un pipeline TFX (es decir, sin utilizar componentes TFX). Utilizará TFDV para inferir un esquema y registrar toda la información sobre este proceso. Esto mostrará cómo se relacionan los diferentes componentes entre sí para que puedas interactuar mejor con la base de datos cuando vuelvas a usar TFX en los próximos laboratorios. Además, conocer el funcionamiento interno de la librería te ayudará a adaptarla a otras plataformas si es necesario.\n",
    "\n",
    "¡Vamos a ello!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "reported-howard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.6.0\n",
      "TFDV version: 1.3.0\n"
     ]
    }
   ],
   "source": [
    "from ml_metadata.metadata_store import metadata_store\n",
    "from ml_metadata.proto import metadata_store_pb2\n",
    "\n",
    "import tensorflow as tf\n",
    "print('TF version: {}'.format(tf.__version__))\n",
    "\n",
    "import tensorflow_data_validation as tfdv\n",
    "print('TFDV version: {}'.format(tfdv.version.__version__))\n",
    "\n",
    "import urllib\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-miami",
   "metadata": {},
   "source": [
    "## Descargar conjunto de datos\n",
    "\n",
    "Para este laboratorio utilizará el conjunto de datos [Chicago Taxi](https://data.cityofchicago.org/Transportation/Taxi-Trips/wrvz-psew). Vamos a descargar los CSV en su espacio de trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "female-responsibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's what we downloaded:\n",
      "data:\n",
      "census_data  eval  serving  train\n",
      "\n",
      "data/census_data:\n",
      "adult.data\n",
      "\n",
      "data/eval:\n",
      "data.csv\n",
      "\n",
      "data/serving:\n",
      "data.csv\n",
      "\n",
      "data/train:\n",
      "data.csv\n"
     ]
    }
   ],
   "source": [
    "# Descargue el archivo zip de GCP y descomprímalo\n",
    "url = 'https://storage.googleapis.com/artifacts.tfx-oss-public.appspot.com/datasets/chicago_data.zip'\n",
    "zip, headers = urllib.request.urlretrieve(url)\n",
    "zipfile.ZipFile(zip).extractall()\n",
    "zipfile.ZipFile(zip).close()\n",
    "\n",
    "print(\"Here's what we downloaded:\")\n",
    "!ls -R data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-current",
   "metadata": {},
   "source": [
    "## Esquema del proceso\n",
    "\n",
    "A continuación se muestra la figura mostrada en clase que describe los diferentes componentes en un almacén de Metadatos ML:\n",
    "\n",
    "<img src='img/mlmd_overview.png' alt='imagen de la vista general de mlmd'>\n",
    "\n",
    "El recuadro verde del centro muestra el modelo de datos seguido de los Metadatos ML. La [documentación oficial](https://www.tensorflow.org/tfx/guide/mlmd#data_model) describe cada uno de ellos y lo mostraremos aquí también para facilitar la referencia:\n",
    "\n",
    "* `ArtifactType` describe el tipo de un artefacto y sus propiedades que se almacenan en el almacén de metadatos. Puedes registrar estos tipos sobre la marcha en el almacén de metadatos en código, o puedes cargarlos en el almacén desde un formato serializado. Una vez registrado un tipo, su definición está disponible durante toda la vida del almacén.\n",
    "* Un `Artifact` describe una instancia específica de un ArtifactType, y sus propiedades que se escriben en el almacén de metadatos.\n",
    "* Un \"Tipo de Ejecución\" describe un tipo de componente o paso en un flujo de trabajo, y sus parámetros de ejecución.\n",
    "* Una \"Ejecución\" es un registro de la ejecución de un componente o un paso en un flujo de trabajo de ML y los parámetros de tiempo de ejecución. Una ejecución puede ser considerada como una instancia de un ExecutionType. Las ejecuciones se registran cuando se ejecuta una tubería o un paso de ML.\n",
    "* Un `Evento` es un registro de la relación entre artefactos y ejecuciones. Cuando ocurre una ejecución, los eventos registran cada artefacto que fue utilizado por la ejecución, y cada artefacto que fue producido. Estos registros permiten el seguimiento del linaje a través de un flujo de trabajo. Al mirar todos los eventos, MLMD sabe qué ejecuciones ocurrieron y qué artefactos se crearon como resultado. MLMD puede entonces recurrir desde cualquier artefacto a todas sus entradas anteriores.\n",
    "* Un `ContextType` describe un tipo de grupo conceptual de artefactos y ejecuciones en un flujo de trabajo, y sus propiedades estructurales. Por ejemplo: proyectos, ejecuciones de pipeline, experimentos, propietarios, etc.\n",
    "* Un \"contexto\" es una instancia de un tipo de contexto. Captura la información compartida dentro del grupo. Por ejemplo: el nombre del proyecto, el identificador de la lista de cambios, las anotaciones de los experimentos, etc. Tiene un nombre único definido por el usuario dentro de su ContextType.\n",
    "* Una \"Atribución\" es un registro de la relación entre artefactos y contextos.\n",
    "* Una \"Asociación\" es un registro de la relación entre ejecuciones y contextos.\n",
    "\n",
    "Como se mencionó anteriormente, se utilizará TFDV para generar un esquema y registrar este proceso en el almacén de metadatos de ML. Empezarás desde cero, por lo que definirás cada componente del modelo de datos. El esquema de pasos implica:\n",
    "\n",
    "1. Definir la base de datos de almacenamiento de ML Metadata\n",
    "1. Configurar los tipos de artefactos necesarios\n",
    "1. Configuración de los tipos de ejecución\n",
    "1. Generación de una unidad de artefacto de entrada\n",
    "1. Generación de una unidad de ejecución\n",
    "1. Registro de un evento de entrada\n",
    "1. Ejecución del componente TFDV\n",
    "1. Generar una unidad de artefacto de salida\n",
    "1. Registro de un evento de salida\n",
    "1. Actualizar la unidad de ejecución\n",
    "1. Configuración y generación de una unidad de contexto\n",
    "1. Generación de atribuciones y asociaciones\n",
    "\n",
    "A continuación, puede recuperar información de la base de datos para investigar aspectos de su proyecto. Por ejemplo, puede encontrar qué conjunto de datos se utilizó para generar un esquema concreto. También lo hará en este ejercicio.\n",
    "\n",
    "Para cada uno de estos pasos, es posible que quieras tener la [documentación de la API de MetadataStore](https://www.tensorflow.org/tfx/ml_metadata/api_docs/python/mlmd/MetadataStore) abierta para que puedas buscar cualquiera de los métodos que vas a utilizar para interactuar con el almacén de metadatos. También puedes consultar el buffer del protocolo `metadata_store` [aquí](https://github.com/google/ml-metadata/blob/r0.24.0/ml_metadata/proto/metadata_store.proto) para ver las descripciones de cada tipo de datos que se tratan en este tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-angle",
   "metadata": {},
   "source": [
    "## Definir la base de datos de almacenamiento de ML Metadata\n",
    "\n",
    "El primer paso sería instanciar su backend de almacenamiento. Como se mencionó en la clase, hay varios tipos soportados como la base de datos falsa (temporal), SQLite, MySQL, e incluso el almacenamiento basado en la nube. Para esta demostración, sólo se utilizará una base de datos falsa para una rápida experimentación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "regulated-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar una conexión config\n",
    "connection_config = metadata_store_pb2.ConnectionConfig()\n",
    "\n",
    "# Establecer una base de datos falsa proto vacia \n",
    "connection_config.fake_database.SetInParent() \n",
    "\n",
    "# Configurar el almacén de metadatos\n",
    "store = metadata_store.MetadataStore(connection_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-beauty",
   "metadata": {},
   "source": [
    "## Registrar tipos de artefactos\n",
    "\n",
    "A continuación, crearemos los tipos de artefactos necesarios y los registraremos en el almacén. Dado que nuestro sencillo ejercicio sólo implicará la generación de un esquema utilizando TFDV, sólo crearás dos tipos de artefactos: uno para el **conjunto de datos de entrada** y otro para el **esquema de salida**. Los pasos principales serán:\n",
    "\n",
    "* Declarar un `ArtifactType()`.\n",
    "* Definir el nombre del tipo de artefacto\n",
    "* Definir las propiedades necesarias dentro de estos tipos de artefactos. Por ejemplo, es importante conocer el nombre de la división de los datos, por lo que puede querer tener una propiedad `split` para el tipo de artefacto que contiene conjuntos de datos.\n",
    "* Usa `put_artifact_type()` para registrarlos en el almacén de metadatos. Esto genera un `id` que puedes usar más tarde para referirte a un tipo de artefacto en particular.\n",
    "\n",
    "*Bonus: Para practicar, también puedes extender el código de abajo para crear un tipo de artefacto para las estadísticas.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "younger-screening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data artifact type:\n",
      " name: \"DataSet\"\n",
      "properties {\n",
      "  key: \"nombre\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"split\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "\n",
      "Schema artifact type:\n",
      " name: \"Schema\"\n",
      "properties {\n",
      "  key: \"nombre\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "\n",
      "Data artifact type ID: 10\n",
      "Schema artifact type ID: 11\n"
     ]
    }
   ],
   "source": [
    "# Crear ArtifactType para el conjunto de datos de entrada\n",
    "data_artifact_type = metadata_store_pb2.ArtifactType()\n",
    "data_artifact_type.name = 'DataSet'\n",
    "data_artifact_type.properties['nombre'] = metadata_store_pb2.STRING\n",
    "data_artifact_type.properties['split'] = metadata_store_pb2.STRING\n",
    "data_artifact_type.properties['version'] = metadata_store_pb2.INT\n",
    "\n",
    "# Registrar el tipo de artefacto en el almacén de metadatos\n",
    "data_artifact_type_id = store.put_artifact_type(data_artifact_type)\n",
    "\n",
    "# Crear ArtifactType para el esquema\n",
    "schema_artifact_type = metadata_store_pb2.ArtifactType()\n",
    "schema_artifact_type.name = 'Schema'\n",
    "schema_artifact_type.properties['nombre'] = metadata_store_pb2.STRING\n",
    "schema_artifact_type.properties['version'] = metadata_store_pb2.INT\n",
    "\n",
    "# Registrar el tipo de artefacto en el almacén de metadatos\n",
    "schema_artifact_type_id = store.put_artifact_type(schema_artifact_type)\n",
    "\n",
    "print('Data artifact type:\\n', data_artifact_type)\n",
    "print('Schema artifact type:\\n', schema_artifact_type)\n",
    "print('Data artifact type ID:', data_artifact_type_id)\n",
    "print('Schema artifact type ID:', schema_artifact_type_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-fleet",
   "metadata": {},
   "source": [
    "## Register ExecutionType\n",
    "\n",
    "A continuación, crearás los tipos de ejecución necesarios. Para la configuración simple, sólo declarará uno para el componente de validación de datos con una propiedad `state` para poder registrar si el proceso se está ejecutando o ya ha terminado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "reflected-oasis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data validation execution type:\n",
      " name: \"Data Validation\"\n",
      "properties {\n",
      "  key: \"state\"\n",
      "  value: STRING\n",
      "}\n",
      "\n",
      "Data validation execution type ID: 12\n"
     ]
    }
   ],
   "source": [
    "# Crear ExecutionType para el componente de Validación de Datos\n",
    "dv_execution_type = metadata_store_pb2.ExecutionType()\n",
    "dv_execution_type.name = 'Data Validation'\n",
    "dv_execution_type.properties['state'] = metadata_store_pb2.STRING\n",
    "\n",
    "# Registrar el tipo de ejecución en el almacén de metadatos\n",
    "dv_execution_type_id = store.put_execution_type(dv_execution_type)\n",
    "\n",
    "print('Data validation execution type:\\n', dv_execution_type)\n",
    "print('Data validation execution type ID:', dv_execution_type_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-station",
   "metadata": {},
   "source": [
    "## Generar unidad de artefacto de entrada\n",
    "\n",
    "Con los tipos de artefactos creados, ahora puede crear instancias de esos tipos. La celda de abajo crea el artefacto para el conjunto de datos de entrada. Este artefacto se registra en el almacén de metadatos a través de la función `put_artifacts()`. De nuevo, genera un `id` que puede ser utilizado como referencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "incoming-prevention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data artifact:\n",
      " type_id: 10\n",
      "uri: \"./data/train/data.csv\"\n",
      "properties {\n",
      "  key: \"nombre\"\n",
      "  value {\n",
      "    string_value: \"Chicago Taxi dataset\"\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"split\"\n",
      "  value {\n",
      "    string_value: \"train\"\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value {\n",
      "    int_value: 1\n",
      "  }\n",
      "}\n",
      "\n",
      "Data artifact ID: 1\n"
     ]
    }
   ],
   "source": [
    "# Declarar artefacto de entrada de tipo DataSet\n",
    "data_artifact = metadata_store_pb2.Artifact()\n",
    "data_artifact.uri = './data/train/data.csv'\n",
    "data_artifact.type_id = data_artifact_type_id\n",
    "data_artifact.properties['nombre'].string_value = 'Chicago Taxi dataset'\n",
    "data_artifact.properties['split'].string_value = 'train'\n",
    "data_artifact.properties['version'].int_value = 1\n",
    "\n",
    "# Enviar el artefacto de entrada al almacén de metadatos\n",
    "data_artifact_id = store.put_artifacts([data_artifact])[0]\n",
    "\n",
    "print('Data artifact:\\n', data_artifact)\n",
    "print('Data artifact ID:', data_artifact_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-visibility",
   "metadata": {},
   "source": [
    "## Generar unidad de ejecución\n",
    "\n",
    "A continuación, crearás una instancia del tipo de ejecución `Validación de Datos` que registraste anteriormente. Establecerás el estado a `RUNNING` para indicar que estás a punto de ejecutar la función TFDV. Esto se registra con la función `put_executions()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "certified-replication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data validation execution:\n",
      " type_id: 12\n",
      "properties {\n",
      "  key: \"state\"\n",
      "  value {\n",
      "    string_value: \"RUNNING\"\n",
      "  }\n",
      "}\n",
      "\n",
      "Data validation execution ID: 1\n"
     ]
    }
   ],
   "source": [
    "# Register the Execution of a Data Validation run\n",
    "dv_execution = metadata_store_pb2.Execution()\n",
    "dv_execution.type_id = dv_execution_type_id\n",
    "dv_execution.properties['state'].string_value = 'RUNNING'\n",
    "\n",
    "# Submit execution unit to the Metadata Store\n",
    "dv_execution_id = store.put_executions([dv_execution])[0]\n",
    "\n",
    "print('Data validation execution:\\n', dv_execution)\n",
    "print('Data validation execution ID:', dv_execution_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-czech",
   "metadata": {},
   "source": [
    "## Registrar evento de entrada\n",
    "\n",
    "Un evento define una relación entre artefactos y ejecuciones. Se generará la relación de eventos de entrada para las unidades de ejecución de conjuntos de datos y de validación de datos. La lista de tipos de eventos se muestra [aquí](https://github.com/google/ml-metadata/blob/master/ml_metadata/proto/metadata_store.proto#L187) y el evento se registra con la función `put_events()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "major-default",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input event:\n",
      " artifact_id: 1\n",
      "execution_id: 1\n",
      "type: DECLARED_INPUT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Declarar el evento de entrada\n",
    "input_event = metadata_store_pb2.Event()\n",
    "input_event.artifact_id = data_artifact_id\n",
    "input_event.execution_id = dv_execution_id\n",
    "input_event.type = metadata_store_pb2.Event.DECLARED_INPUT\n",
    "\n",
    "# Submit input event to the Metadata Store\n",
    "store.put_events([input_event])\n",
    "\n",
    "print('Input event:\\n', input_event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-fossil",
   "metadata": {},
   "source": [
    "## Ejecutar el componente TFDV\n",
    "\n",
    "Ahora ejecutará el componente TFDV para generar el esquema del conjunto de datos. Esto debería resultarle familiar ya que lo ha hecho en la semana 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "environmental-shakespeare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.8 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tensorflow_data_validation/utils/stats_util.py:247: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tensorflow_data_validation/utils/stats_util.py:247: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset's Schema has been generated at: ./schema.pbtxt\n"
     ]
    }
   ],
   "source": [
    "# Infer a schema by passing statistics to `infer_schema()`\n",
    "train_data = './data/train/data.csv'\n",
    "train_stats = tfdv.generate_statistics_from_csv(data_location=train_data)\n",
    "schema = tfdv.infer_schema(statistics=train_stats)\n",
    "\n",
    "schema_file = './schema.pbtxt'\n",
    "tfdv.write_schema_text(schema, schema_file)\n",
    "\n",
    "print(\"Dataset's Schema has been generated at:\", schema_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-diana",
   "metadata": {},
   "source": [
    "## Generar unidad de artefacto de salida\n",
    "\n",
    "Ahora que el componente TFDV ha terminado de ejecutarse y se ha generado el esquema, puede crear el artefacto para el esquema generado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "recent-spencer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema artifact:\n",
      " type_id: 11\n",
      "uri: \"./schema.pbtxt\"\n",
      "properties {\n",
      "  key: \"nombre\"\n",
      "  value {\n",
      "    string_value: \"Chicago Taxi Schema\"\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value {\n",
      "    int_value: 1\n",
      "  }\n",
      "}\n",
      "\n",
      "Schema artifact ID: 2\n"
     ]
    }
   ],
   "source": [
    "# Declare output artifact of type Schema_artifact\n",
    "schema_artifact = metadata_store_pb2.Artifact()\n",
    "schema_artifact.uri = schema_file\n",
    "schema_artifact.type_id = schema_artifact_type_id\n",
    "schema_artifact.properties['version'].int_value = 1\n",
    "schema_artifact.properties['nombre'].string_value = 'Chicago Taxi Schema'\n",
    "\n",
    "# Submit output artifact to the Metadata Store\n",
    "schema_artifact_id = store.put_artifacts([schema_artifact])[0]\n",
    "\n",
    "print('Schema artifact:\\n', schema_artifact)\n",
    "print('Schema artifact ID:', schema_artifact_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-underground",
   "metadata": {},
   "source": [
    "## Registrar evento de salida\n",
    "\n",
    "De forma análoga al evento de entrada anterior, también se quiere definir un evento de salida para registrar el artefacto de salida de una unidad de ejecución concreta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "opponent-invitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output event:\n",
      " artifact_id: 2\n",
      "execution_id: 1\n",
      "type: DECLARED_OUTPUT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Declare the output event\n",
    "output_event = metadata_store_pb2.Event()\n",
    "output_event.artifact_id = schema_artifact_id\n",
    "output_event.execution_id = dv_execution_id\n",
    "output_event.type = metadata_store_pb2.Event.DECLARED_OUTPUT\n",
    "\n",
    "# Submit output event to the Metadata Store\n",
    "store.put_events([output_event])\n",
    "\n",
    "print('Output event:\\n', output_event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-burst",
   "metadata": {},
   "source": [
    "## Actualizar la unidad de ejecución\n",
    "\n",
    "Como el componente TFDV ha terminado de ejecutarse con éxito, es necesario actualizar el `estado` de la unidad de ejecución y registrarlo de nuevo en el almacén."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "processed-wealth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data validation execution:\n",
      " id: 1\n",
      "type_id: 12\n",
      "properties {\n",
      "  key: \"state\"\n",
      "  value {\n",
      "    string_value: \"COMPLETED\"\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mark the `state` as `COMPLETED`\n",
    "dv_execution.id = dv_execution_id\n",
    "dv_execution.properties['state'].string_value = 'COMPLETED'\n",
    "\n",
    "# Update execution unit in the Metadata Store\n",
    "store.put_executions([dv_execution])\n",
    "\n",
    "print('Data validation execution:\\n', dv_execution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-plant",
   "metadata": {},
   "source": [
    "## Configuración de tipos de contexto y generación de una unidad de contexto\n",
    "\n",
    "Puede agrupar los artefactos y las unidades de ejecución en un `Contexto`. En primer lugar, es necesario definir un `ContextType` que defina el contexto requerido. Sigue un formato similar al de los tipos de artefactos y eventos. Puedes registrarlo con la función `put_context_type()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "declared-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ContextType\n",
    "expt_context_type = metadata_store_pb2.ContextType()\n",
    "expt_context_type.name = 'Experiment'\n",
    "expt_context_type.properties['note'] = metadata_store_pb2.STRING\n",
    "\n",
    "# Register context type to the Metadata Store\n",
    "expt_context_type_id = store.put_context_type(expt_context_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-cause",
   "metadata": {},
   "source": [
    "Del mismo modo, puede crear una instancia de este tipo de contexto y utilizar el método `put_contexts()` para registrarse en el almacén."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fifth-charter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Context type:\n",
      " name: \"Experiment\"\n",
      "properties {\n",
      "  key: \"note\"\n",
      "  value: STRING\n",
      "}\n",
      "\n",
      "Experiment Context type ID:  13\n",
      "Experiment Context:\n",
      " type_id: 13\n",
      "name: \"Demo\"\n",
      "properties {\n",
      "  key: \"note\"\n",
      "  value {\n",
      "    string_value: \"Walkthrough of metadata\"\n",
      "  }\n",
      "}\n",
      "\n",
      "Experiment Context ID:  1\n"
     ]
    }
   ],
   "source": [
    "# Generate the context\n",
    "expt_context = metadata_store_pb2.Context()\n",
    "expt_context.type_id = expt_context_type_id\n",
    "# Give the experiment a name\n",
    "expt_context.name = 'Demo'\n",
    "expt_context.properties['note'].string_value = 'Walkthrough of metadata'\n",
    "\n",
    "# Submit context to the Metadata Store\n",
    "expt_context_id = store.put_contexts([expt_context])[0]\n",
    "\n",
    "print('Experiment Context type:\\n', expt_context_type)\n",
    "print('Experiment Context type ID: ', expt_context_type_id)\n",
    "\n",
    "print('Experiment Context:\\n', expt_context)\n",
    "print('Experiment Context ID: ', expt_context_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-modification",
   "metadata": {},
   "source": [
    "## Generar relaciones de atribución y asociación\n",
    "\n",
    "Con el `Contexto` definido, ahora puedes crear su relación con el artefacto y las ejecuciones que utilizaste previamente. Crearás la relación entre la unidad de artefacto del esquema y la unidad de contexto del experimento para formar una `Atribución`.\n",
    "Del mismo modo, crearás la relación entre la unidad de ejecución de validación de datos y la unidad de contexto del experimento para formar una `Asociación`. Estas se registran con el método `put_attributions_and_associations()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bigger-masters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Attribution:\n",
      " artifact_id: 2\n",
      "context_id: 1\n",
      "\n",
      "Experiment Association:\n",
      " execution_id: 1\n",
      "context_id: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate the attribution\n",
    "expt_attribution = metadata_store_pb2.Attribution()\n",
    "expt_attribution.artifact_id = schema_artifact_id\n",
    "expt_attribution.context_id = expt_context_id\n",
    "\n",
    "# Generate the association\n",
    "expt_association = metadata_store_pb2.Association()\n",
    "expt_association.execution_id = dv_execution_id\n",
    "expt_association.context_id = expt_context_id\n",
    "\n",
    "# Submit attribution and association to the Metadata Store\n",
    "store.put_attributions_and_associations([expt_attribution], [expt_association])\n",
    "\n",
    "print('Experiment Attribution:\\n', expt_attribution)\n",
    "print('Experiment Association:\\n', expt_association)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-sunglasses",
   "metadata": {},
   "source": [
    "## Recuperación de la información del almacén de metadatos\n",
    "\n",
    "Ahora has registrado la información necesaria en el almacén de metadatos. Si hicimos esto en una base de datos persistente, puedes rastrear qué artefactos y eventos están relacionados entre sí incluso sin ver el código utilizado para generarlo. Vea un ejemplo de ejecución a continuación donde se investiga qué conjunto de datos se utiliza para generar el esquema. (**Es obvio qué conjunto de datos se utiliza en nuestra sencilla demostración porque sólo tenemos dos artefactos registrados. Por lo tanto, suponga que tiene miles de entradas en el almacén de metadatos*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "careful-gambling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: 10\n",
       " name: \"DataSet\"\n",
       " properties {\n",
       "   key: \"nombre\"\n",
       "   value: STRING\n",
       " }\n",
       " properties {\n",
       "   key: \"split\"\n",
       "   value: STRING\n",
       " }\n",
       " properties {\n",
       "   key: \"version\"\n",
       "   value: INT\n",
       " },\n",
       " id: 11\n",
       " name: \"Schema\"\n",
       " properties {\n",
       "   key: \"nombre\"\n",
       "   value: STRING\n",
       " }\n",
       " properties {\n",
       "   key: \"version\"\n",
       "   value: INT\n",
       " }]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get artifact types\n",
    "store.get_artifact_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "strange-replacement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 2\n",
      "type_id: 11\n",
      "uri: \"./schema.pbtxt\"\n",
      "properties {\n",
      "  key: \"nombre\"\n",
      "  value {\n",
      "    string_value: \"Chicago Taxi Schema\"\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value {\n",
      "    int_value: 1\n",
      "  }\n",
      "}\n",
      "create_time_since_epoch: 1667420946878\n",
      "last_update_time_since_epoch: 1667420946878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtener el primer elemento de la lista de artefactos `Schema`.\n",
    "# Investigarás qué conjunto de datos se utilizó para generarlo.\n",
    "\n",
    "schema_to_inv = store.get_artifacts_by_type('Schema')[0]\n",
    "\n",
    "# print output\n",
    "print(schema_to_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "lesbian-butler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[artifact_id: 2\n",
      "execution_id: 1\n",
      "type: DECLARED_OUTPUT\n",
      "milliseconds_since_epoch: 1667421026595\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Get events related to the schema id\n",
    "schema_events = store.get_events_by_artifact_ids([schema_to_inv.id])\n",
    "\n",
    "print(schema_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-family",
   "metadata": {},
   "source": [
    "Se ve que es una salida de una ejecución por lo que se puede buscar el id de la ejecución para ver los artefactos relacionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "engaging-clock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[artifact_id: 1\n",
      "execution_id: 1\n",
      "type: DECLARED_INPUT\n",
      "milliseconds_since_epoch: 1667420834390\n",
      ", artifact_id: 2\n",
      "execution_id: 1\n",
      "type: DECLARED_OUTPUT\n",
      "milliseconds_since_epoch: 1667421026595\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Get events related to the output above\n",
    "execution_events = store.get_events_by_execution_ids([schema_events[0].execution_id])\n",
    "\n",
    "print(execution_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-hurricane",
   "metadata": {},
   "source": [
    "Verás la entrada declarada de esta ejecución para que puedas seleccionarla de la lista y buscar los detalles del artefacto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "greek-hebrew",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: 1\n",
       " type_id: 10\n",
       " uri: \"./data/train/data.csv\"\n",
       " properties {\n",
       "   key: \"nombre\"\n",
       "   value {\n",
       "     string_value: \"Chicago Taxi dataset\"\n",
       "   }\n",
       " }\n",
       " properties {\n",
       "   key: \"split\"\n",
       "   value {\n",
       "     string_value: \"train\"\n",
       "   }\n",
       " }\n",
       " properties {\n",
       "   key: \"version\"\n",
       "   value {\n",
       "     int_value: 1\n",
       "   }\n",
       " }\n",
       " create_time_since_epoch: 1667420711333\n",
       " last_update_time_since_epoch: 1667420711333]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look up the artifact that is a declared input\n",
    "artifact_input = execution_events[0]\n",
    "\n",
    "store.get_artifacts_by_id([artifact_input.artifact_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-remainder",
   "metadata": {},
   "source": [
    "Muy bien. Ahora has obtenido el artefacto del conjunto de datos que se utilizó para generar el esquema. Puedes abordar esto de otra manera y te instamos a que practiques utilizando los diferentes métodos de la API de MetadataStore para familiarizarte con la interacción con la base de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-motorcycle",
   "metadata": {},
   "source": [
    "### Recapitulación\n",
    "\n",
    "En este cuaderno, has podido practicar el uso de ML Metadata fuera de TFX. Esto debería ayudarte a entender su funcionamiento interno para que sepas mejor cómo consultar los almacenes de ML Metadata o incluso configurarlo para tus propios casos de uso. TFX aprovecha esta biblioteca para mantener los registros de las ejecuciones del pipeline y podrás ver más de eso en los próximos laboratorios. A continuación, se revisará cómo trabajar con esquemas y en el próximo cuaderno, se verá cómo se puede implementar en una tubería TFX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-design",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
