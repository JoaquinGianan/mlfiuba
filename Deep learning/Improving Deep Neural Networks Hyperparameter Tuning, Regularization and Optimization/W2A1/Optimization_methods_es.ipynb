{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos de optimización\n",
    "\n",
    "Hasta ahora, siempre has utilizado el Descenso Gradiente para actualizar los parámetros y minimizar el coste. En este cuaderno, adquirirás habilidades con algunos métodos de optimización más avanzados que pueden acelerar el aprendizaje y quizás incluso conseguir un mejor valor final para la función de coste. Tener un buen algoritmo de optimización puede ser la diferencia entre esperar días o sólo unas horas para obtener un buen resultado. \n",
    "\n",
    "Al final de este cuaderno, usted será capaz de: \n",
    "\n",
    "* Aplicar métodos de optimización como el Gradient Descent (estocástico), Momentum, RMSProp y Adam\n",
    "* Utilizar minibatches aleatorios para acelerar la convergencia y mejorar la optimización\n",
    "\n",
    "El descenso de gradiente va \"cuesta abajo\" en una función de coste $J$. Piense que trata de hacer lo siguiente \n",
    "<img src=\"images/cost.jpg\" style=\"width:650px;height:300px;\">\n",
    "<caption><center> <u> <b>Figure 1</b> </u>: <b>Minimizar el coste es como encontrar el punto más bajo en un paisaje accidentado</b><br> En cada paso del entrenamiento, se actualizan los parámetros siguiendo una determinada dirección para intentar llegar al punto más bajo posible. </center></caption>\n",
    "\n",
    "\n",
    "**Notaciones**: Como siempre, $\\frac{{parcial J}{parcial a } = $ `da` para cualquier variable `a`.\n",
    "\n",
    "¡Empecemos!\n",
    "\n",
    "## Nota importante sobre el envío al AutoGrader\n",
    "\n",
    "Antes de enviar su tarea al AutoGrader, por favor asegúrese de que no está haciendo lo siguiente:\n",
    "\n",
    "1. 1. No ha añadido ninguna declaración _extra_ `print` en la tarea.\n",
    "2. 2. No ha añadido ninguna celda de código _extra_ en la tarea.\n",
    "3. No ha cambiado ningún parámetro de la función.\n",
    "4. No ha utilizado ninguna variable global dentro de sus ejercicios calificados. A menos que se le indique específicamente que lo haga, por favor absténgase de hacerlo y utilice las variables locales en su lugar.\n",
    "5. 5. No está cambiando el código de asignación donde no es necesario, como la creación de variables _extra_.\n",
    "\n",
    "Si hace algo de lo siguiente, obtendrá un error como `Grader no encontrado` (o similarmente inesperado) al enviar su tarea. Antes de pedir ayuda/depurar los errores de su tarea, compruebe esto primero. Si este es el caso, y no recuerda los cambios que ha realizado, puede obtener una nueva copia de la tarea siguiendo estas [instrucciones](https://www.coursera.org/learn/deep-neural-network/supplement/QWEnZ/h-ow-to-refresh-your-workspace)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [1- Packages](#1)\n",
    "- [2 - Gradient Descent](#2)\n",
    "    - [Exercise 1 - update_parameters_with_gd](#ex-1)\n",
    "- [3 - Mini-Batch Gradient Descent](#3)\n",
    "    - [Exercise 2 - random_mini_batches](#ex-2)\n",
    "- [4 - Momentum](#4)\n",
    "    - [Exercise 3 - initialize_velocity](#ex-3)\n",
    "    - [Exercise 4 - update_parameters_with_momentum](#ex-4)\n",
    "- [5 - Adam](#5)\n",
    "    - [Exercise 5 - initialize_adam](#ex-5)\n",
    "    - [Exercise 6 - update_parameters_with_adam](#ex-6)\n",
    "- [6 - Model with different Optimization algorithms](#6)\n",
    "    - [6.1 - Mini-Batch Gradient Descent](#6-1)\n",
    "    - [6.2 - Mini-Batch Gradient Descent with Momentum](#6-2)\n",
    "    - [6.3 - Mini-Batch with Adam](#6-3)\n",
    "    - [6.4 - Summary](#6-4)\n",
    "- [7 - Learning Rate Decay and Scheduling](#7)\n",
    "    - [7.1 - Decay on every iteration](#7-1)\n",
    "        - [Exercise 7 - update_lr](#ex-7)\n",
    "    - [7.2 - Fixed Interval Scheduling](#7-2)\n",
    "        - [Exercise 8 - schedule_lr_decay](#ex-8)\n",
    "    - [7.3 - Using Learning Rate Decay for each Optimization Method](#7-3)\n",
    "        - [7.3.1 - Gradient Descent with Learning Rate Decay](#7-3-1)\n",
    "        - [7.3.2 - Gradient Descent with Momentum and Learning Rate Decay](#7-3-2)\n",
    "        - [7.3.3 - Adam with Learning Rate Decay](#7-3-3)\n",
    "    - [7.4 - Achieving similar performance with different methods](#7-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import math\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "\n",
    "from opt_utils_v1a import load_params_and_grads, initialize_parameters, forward_propagation, backward_propagation\n",
    "from opt_utils_v1a import compute_cost, predict, predict_dec, plot_decision_boundary, load_dataset\n",
    "from copy import deepcopy\n",
    "from testCases import *\n",
    "from public_tests import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (7.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Descenso de gradiente\n",
    "\n",
    "Un método de optimización simple en el aprendizaje automático es el descenso de gradiente (GD). Cuando se toman pasos de gradiente con respecto a todos los $m$ ejemplos en cada paso, también se llama Batch Gradient Descent.\n",
    "\n",
    "<a name='ex-1'></a>\n",
    "### Ejercicio 1 - actualizar_parámetros_con_gd\n",
    "\n",
    "Implementar la regla de actualización de descenso de gradiente. La regla de descenso de gradiente es, para $l = 1, ..., L$: \n",
    "\n",
    "$$ W^{[l]} = W^{[l]} - \\alpha \\text{ } dW^{[l]} \\tag{1}$$\n",
    "$$ b^{[l]} = b^{[l]} - \\alpha \\text{ } db^{[l]} \\tag{2}$$\n",
    "\n",
    "donde L es el número de capas y $\\alpha$ es la tasa de aprendizaje. Todos los parámetros deben ser almacenados en el diccionario `parameters`. Tenga en cuenta que el iterador `l` comienza en 1 en el bucle `for` ya que los primeros parámetros son $W^{[1]}$ y $b^{[1]}$.\n",
    "\n",
    "<details><summary>Code</summary>\n",
    "\n",
    "```python    \n",
    "    parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate * grads['dW' + str(l)]\n",
    "    parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate * grads['db' + str(l)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: update_parameters_with_gd\n",
    "\n",
    "def update_parameters_with_gd(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Actualizar los parámetros utilizando un paso de descenso de gradiente\n",
    "    \n",
    "    Argumentos:\n",
    "    parameters -- diccionario python que contiene los parámetros a actualizar:\n",
    "                    parameters['W' + str(l)] = Wl\n",
    "                    parameters['b' + str(l)] = bl\n",
    "    grads -- diccionario de python que contiene sus gradientes para actualizar cada uno de los parámetros:\n",
    "                    grads['dW' + str(l)] = dWl\n",
    "                    grads['db' + str(l)] = dbl\n",
    "    learning_rate -- la tasa de aprendizaje, escalar.\n",
    "    \n",
    "    Devuelve:\n",
    "    parameters -- diccionario python que contiene sus parámetros actualizados \n",
    "    \"\"\"\n",
    "    L = len(parameters) // 2 # number of layers in the neural networks\n",
    "\n",
    "    # Update rule for each parameter\n",
    "    for l in range(1, L + 1):\n",
    "        # (approx. 2 lines)\n",
    "        # parameters[\"W\" + str(l)] =  \n",
    "        # parameters[\"b\" + str(l)] = \n",
    "        # YOUR CODE STARTS HERE\n",
    "        parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate * grads['dW' + str(l)]\n",
    "        parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate * grads['db' + str(l)]\n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 =\n",
      "[[ 1.63535156 -0.62320365 -0.53718766]\n",
      " [-1.07799357  0.85639907 -2.29470142]]\n",
      "b1 =\n",
      "[[ 1.74604067]\n",
      " [-0.75184921]]\n",
      "W2 =\n",
      "[[ 0.32171798 -0.25467393  1.46902454]\n",
      " [-2.05617317 -0.31554548 -0.3756023 ]\n",
      " [ 1.1404819  -1.09976462 -0.1612551 ]]\n",
      "b2 =\n",
      "[[-0.88020257]\n",
      " [ 0.02561572]\n",
      " [ 0.57539477]]\n",
      "\u001b[92mAll test passed\n"
     ]
    }
   ],
   "source": [
    "parameters, grads, learning_rate = update_parameters_with_gd_test_case()\n",
    "learning_rate = 0.01\n",
    "parameters = update_parameters_with_gd(parameters, grads, learning_rate)\n",
    "\n",
    "print(\"W1 =\\n\" + str(parameters[\"W1\"]))\n",
    "print(\"b1 =\\n\" + str(parameters[\"b1\"]))\n",
    "print(\"W2 =\\n\" + str(parameters[\"W2\"]))\n",
    "print(\"b2 =\\n\" + str(parameters[\"b2\"]))\n",
    "\n",
    "update_parameters_with_gd_test(update_parameters_with_gd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una variante de esto es el Descenso Gradiente Estocástico (SGD), que es equivalente al descenso gradiente en mini lotes, donde cada mini lote tiene sólo 1 ejemplo. La regla de actualización que acaba de implementar no cambia. Lo que cambia es que usted calcularía los gradientes en un solo ejemplo de entrenamiento a la vez, en lugar de en todo el conjunto de entrenamiento. Los siguientes ejemplos de código ilustran la diferencia entre el descenso de gradiente estocástico y el descenso de gradiente (por lotes). \n",
    "\n",
    "- Descenso de gradiente (por lotes)**:\n",
    "\n",
    "``` python\n",
    "X = data_input\n",
    "Y = labels\n",
    "m = X.shape[1]  # Number of training examples\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "for i in range(0, num_iterations):\n",
    "    # Forward propagation\n",
    "    a, caches = forward_propagation(X, parameters)\n",
    "    # Compute cost\n",
    "    cost_total = compute_cost(a, Y)  # Cost for m training examples\n",
    "    # Backward propagation\n",
    "    grads = backward_propagation(a, caches, parameters)\n",
    "    # Update parameters\n",
    "    parameters = update_parameters(parameters, grads)\n",
    "    # Compute average cost\n",
    "    cost_avg = cost_total / m\n",
    "        \n",
    "```\n",
    "\n",
    "- **Stochastic Gradient Descent**:\n",
    "\n",
    "```python\n",
    "X = data_input\n",
    "Y = labels\n",
    "m = X.shape[1]  # Number of training examples\n",
    "parameters = initialize_parameters(layers_dims)\n",
    "for i in range(0, num_iterations):\n",
    "    cost_total = 0\n",
    "    for j in range(0, m):\n",
    "        # Forward propagation\n",
    "        a, caches = forward_propagation(X[:,j], parameters)\n",
    "        # Compute cost\n",
    "        cost_total += compute_cost(a, Y[:,j])  # Cost for one training example\n",
    "        # Backward propagation\n",
    "        grads = backward_propagation(a, caches, parameters)\n",
    "        # Update parameters\n",
    "        parameters = update_parameters(parameters, grads)\n",
    "    # Compute average cost\n",
    "    cost_avg = cost_total / m\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el Descenso Gradiente Estocástico, sólo se utiliza un ejemplo de entrenamiento antes de actualizar los gradientes. Cuando el conjunto de entrenamiento es grande, el SGD puede ser más rápido. Pero los parámetros \"oscilarán\" hacia el mínimo en lugar de converger suavemente. Esto es lo que parece: \n",
    "\n",
    "<img src=\"images/kiank_sgd.png\" style=\"width:750px;height:250px;\">\n",
    "<caption><center> <u> <font color='purple'> <b>Figure 1</b> </u><font color='purple'>  : <b>SGD vs GD</b><br> \"+\" denota un mínimo del coste. SGD conduce a muchas oscilaciones para alcanzar la convergencia, pero cada paso es mucho más rápido de calcular para SGD que para GD, ya que utiliza sólo un ejemplo de entrenamiento (frente a todo el lote para GD). </center></caption>\n",
    "    \n",
    "**Nótese** también que la implementación de SGD requiere 3 bucles for en total:\n",
    "1. Sobre el número de iteraciones\n",
    "2. Sobre los $m$ ejemplos de entrenamiento\n",
    "3. Sobre las capas (para actualizar todos los parámetros, desde $(W^{[1]},b^{[1]})$ hasta $(W^{[L]},b^{[L]})$)\n",
    "\n",
    "En la práctica, a menudo se obtienen resultados más rápidos si no se utiliza todo el conjunto de entrenamiento, o sólo un ejemplo de entrenamiento, para realizar cada actualización. El descenso de gradiente en mini lotes utiliza un número intermedio de ejemplos para cada paso. Con el descenso de gradiente en mini lotes, se realiza un bucle sobre los mini lotes en lugar de un bucle sobre los ejemplos de entrenamiento individuales.\n",
    "\n",
    "<img src=\"images/kiank_minibatch.png\" style=\"width:750px;height:250px;\">\n",
    "<caption><center> <u> <font color='purple'> <b>Figure 2</b> </u>: <font color='purple'>  <b>SGD vs Mini-Batch GD</b><br> \"+\" denota un mínimo del coste. El uso de mini-lotes en su algoritmo de optimización a menudo conduce a una optimización más rápida. </center></caption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Mini-Lotes de Descenso de Gradientes\n",
    "\n",
    "Ahora construirás algunos mini-lotes a partir del conjunto de entrenamiento (X, Y).\n",
    "\n",
    "Hay dos pasos:\n",
    "- **Shuffle** (Mezclar): Crear una versión mezclasda del conjunto de entrenamiento (X, Y) como se muestra a continuación. Cada columna de X e Y representa un ejemplo de entrenamiento. Obsérvese que el `Shuffle aleatorio` se realiza de forma sincrónica entre X e Y. De tal forma que, tras el mezclado , la columna $i^{th}$ de X es el ejemplo correspondiente a la etiqueta $i^{th}$ de Y. El paso de `Shuffle` garantiza que los ejemplos se dividirán aleatoriamente en diferentes minilotes. \n",
    "\n",
    "<img src=\"images/kiank_shuffle.png\" style=\"width:550px;height:300px;\">\n",
    "\n",
    "- **Partición**: Partición de la mezcla (X, Y) en mini-lotes de tamaño `mini_batch_size` (aquí 64). Tenga en cuenta que el número de ejemplos de entrenamiento no siempre es divisible por `mini_batch_size`. El último mini lote puede ser más pequeño, pero no hay que preocuparse por ello. Cuando el último mini lote es más pequeño que el `mini_batch_size`  completo, tendrá este aspecto: \n",
    "\n",
    "<img src=\"images/kiank_partition.png\" style=\"width:550px;height:300px;\">\n",
    "\n",
    "<a name='ex-2'></a>\n",
    "### Ejercicio 2 - random_mini_batches\n",
    "\n",
    "Implementa `random_mini_batches`. La parte de barajar ya ha sido codificada para ti. Para ayudarte con el paso de partición, se te ha proporcionado el siguiente código que selecciona los índices para los mini-lotes de $1^{st}$ y $2^{nd}$:\n",
    "\n",
    "```python\n",
    "first_mini_batch_X = shuffled_X[:, 0 : mini_batch_size]\n",
    "second_mini_batch_X = shuffled_X[:, mini_batch_size : 2 * mini_batch_size]\n",
    "...\n",
    "```\n",
    "Tenga en cuenta que el último mini lote puede terminar siendo más pequeño que `mini_batch_size=64`. Dejemos que $\\lfloor s \\rfloor$ represente $s$ redondeado al entero más cercano (esto es `math.floor(s)` en Python). Si el número total de ejemplos no es un múltiplo de `mini_batch_size=64` entonces habrá $\\left\\lfloor \\frac{m}{mini_batch_size}\\right\\rfloor$ mini-lotes con un total de 64 ejemplos, y el número de ejemplos en el minilote final será $\\left(m-mini_\\_batch_\\_size \\times \\left\\lfloor \\frac{m}{mini\\_batch\\_size}\\right\\rfloor\\right)$.\n",
    "\n",
    "\n",
    "\n",
    "**Sugerencia:**\n",
    "\n",
    "$$ mini\\_lote\\_X = shuffled\\_X[:, i : j]$$ \n",
    "\n",
    "Piensa en una forma de utilizar la variable del bucle for `k` para ayudarte a incrementar `i` y `j` en múltiplos de mini_batch_size.\n",
    "\n",
    "Como ejemplo, si quieres incrementar en múltiplos de 3, podrías lo siguiente:\n",
    "\n",
    "```python\n",
    "n = 3\n",
    "for k in (0 , 5):\n",
    "    print(k * n)\n",
    "```\n",
    "<details><summary>Code</summary>\n",
    "\n",
    "```python\n",
    "for k in range(0, num_complete_minibatches):\n",
    "        \n",
    "        mini_batch_X = shuffled_X[:, k * inc : (k+1) * inc]\n",
    "        mini_batch_Y = shuffled_Y[:, k * inc : (k+1) * inc]\n",
    "        \n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "if m % mini_batch_size != 0:\n",
    "\n",
    "    mini_batch_X = shuffled_X[:, num_complete_minibatches * inc:]\n",
    "    mini_batch_Y = shuffled_Y[:, num_complete_minibatches * inc:]\n",
    "\n",
    "    mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "    mini_batches.append(mini_batch)    \n",
    "```  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: random_mini_batches\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Crea una lista de minilotes aleatorios a partir de (X, Y)\n",
    "    \n",
    "    Argumentos:\n",
    "    X -- datos de entrada, de forma (tamaño de entrada, número de ejemplos)\n",
    "    Y -- vector \"etiqueta\" verdadera (1 para el punto azul / 0 para el punto rojo), de forma (1, número de ejemplos)\n",
    "    mini_tamaño_del_lote -- tamaño de los mini-lotes, entero\n",
    "    \n",
    "    Devuelve:\n",
    "    mini_lotes -- lista de sincronizados (mini_lotes_X, mini_lotes_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "        \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X  = X[:, permutation]\n",
    "    shuffled_Y  = Y[:, permutation].reshape((1, m))\n",
    "    \n",
    "    inc = mini_batch_size\n",
    "\n",
    "    # Step 2 - Partition (shuffled_X, shuffled_Y).\n",
    "    # Cases with a complete mini batch size only i.e each of 64 examples.\n",
    "    num_complete_minibatches = math.floor(m / mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        # (approx. 2 lines)\n",
    "        # mini_batch_X =  \n",
    "        # mini_batch_Y =\n",
    "        # YOUR CODE STARTS HERE\n",
    "        \n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # For handling the end case (last mini-batch < mini_batch_size i.e less than 64)\n",
    "    if m % mini_batch_size != 0:\n",
    "        #(approx. 2 lines)\n",
    "        # mini_batch_X =\n",
    "        # mini_batch_Y =\n",
    "        # YOUR CODE STARTS HERE\n",
    "        \n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "mini_batch_size = 64\n",
    "nx = 12288\n",
    "m = 148\n",
    "X = np.array([x for x in range(nx * m)]).reshape((m, nx)).T\n",
    "Y = np.random.randn(1, m) < 0.5\n",
    "\n",
    "mini_batches = random_mini_batches(X, Y, mini_batch_size)\n",
    "n_batches = len(mini_batches)\n",
    "\n",
    "assert n_batches == math.ceil(m / mini_batch_size), f\"Wrong number of mini batches. {n_batches} != {math.ceil(m / mini_batch_size)}\"\n",
    "for k in range(n_batches - 1):\n",
    "    assert mini_batches[k][0].shape == (nx, mini_batch_size), f\"Wrong shape in {k} mini batch for X\"\n",
    "    assert mini_batches[k][1].shape == (1, mini_batch_size), f\"Wrong shape in {k} mini batch for Y\"\n",
    "    assert np.sum(np.sum(mini_batches[k][0] - mini_batches[k][0][0], axis=0)) == ((nx * (nx - 1) / 2 ) * mini_batch_size), \"Wrong values. It happens if the order of X rows(features) changes\"\n",
    "if ( m % mini_batch_size > 0):\n",
    "    assert mini_batches[n_batches - 1][0].shape == (nx, m % mini_batch_size), f\"Wrong shape in the last minibatch. {mini_batches[n_batches - 1][0].shape} != {(nx, m % mini_batch_size)}\"\n",
    "\n",
    "assert np.allclose(mini_batches[0][0][0][0:3], [294912,  86016, 454656]), \"Wrong values. Check the indexes used to form the mini batches\"\n",
    "assert np.allclose(mini_batches[-1][0][-1][0:3], [1425407, 1769471, 897023]), \"Wrong values. Check the indexes used to form the mini batches\"\n",
    "\n",
    "print(\"\\033[92mAll test passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_X, t_Y, mini_batch_size = random_mini_batches_test_case()\n",
    "mini_batches = random_mini_batches(t_X, t_Y, mini_batch_size)\n",
    "\n",
    "print (\"shape of the 1st mini_batch_X: \" + str(mini_batches[0][0].shape))\n",
    "print (\"shape of the 2nd mini_batch_X: \" + str(mini_batches[1][0].shape))\n",
    "print (\"shape of the 3rd mini_batch_X: \" + str(mini_batches[2][0].shape))\n",
    "print (\"shape of the 1st mini_batch_Y: \" + str(mini_batches[0][1].shape))\n",
    "print (\"shape of the 2nd mini_batch_Y: \" + str(mini_batches[1][1].shape)) \n",
    "print (\"shape of the 3rd mini_batch_Y: \" + str(mini_batches[2][1].shape))\n",
    "print (\"mini batch sanity check: \" + str(mini_batches[0][0][0][0:3]))\n",
    "\n",
    "random_mini_batches_test(random_mini_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "**Lo que debes recordar**:\n",
    "- Barajar y Particionar son los dos pasos necesarios para construir minilotes\n",
    "- A menudo se eligen potencias de dos para el tamaño del minilote, por ejemplo, 16, 32, 64, 128."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4 - Momentum\n",
    "\n",
    "Dado que el descenso de gradiente por mini lotes realiza una actualización de los parámetros después de ver sólo un subconjunto de ejemplos, la dirección de la actualización tiene cierta varianza, por lo que el camino tomado por el descenso de gradiente por mini lotes \"oscilará\" hacia la convergencia. El uso del impulso puede reducir estas oscilaciones. \n",
    "\n",
    "El impulso tiene en cuenta los gradientes anteriores para suavizar la actualización. La \"dirección\" de los gradientes anteriores se almacena en la variable $v$. Formalmente, será la media ponderada exponencialmente del gradiente en los pasos anteriores. También se puede pensar en $v$ como la \"velocidad\" de una pelota rodando cuesta abajo, acumulando velocidad (e impulso) según la dirección del gradiente/pendiente de la colina. \n",
    "\n",
    "<img src=\"images/opt_momentum.png\" style=\"width:400px;height:250px;\">\n",
    "<caption><center> <u><font color='purple'><b>Figure 3</b> </u><font color='purple'>: Las flechas rojas muestran la dirección que toma un paso del descenso de gradiente por mini lotes con momentum. Los puntos azules muestran la dirección del gradiente (con respecto al mini lote actual) en cada paso. Más que seguir simplemente el gradiente, se permite que el gradiente influya en $v$ y luego dé un paso en la dirección de $v$.<br> <font color='black'> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-3'></a>    \n",
    "### Ejercicio 3 - inicializar_velocidad\n",
    "Inicializar la velocidad. La velocidad, $v$, es un diccionario python que necesita ser inicializado con matrices de ceros. Sus claves son las mismas que las del diccionario `grads`, es decir\n",
    "para $l =1,...,L$:\n",
    "\n",
    "```python\n",
    "v[\"dW\" + str(l)] = ... #(numpy array of zeros with the same shape as parameters[\"W\" + str(l)])\n",
    "v[\"db\" + str(l)] = ... #(numpy array of zeros with the same shape as parameters[\"b\" + str(l)])\n",
    "```\n",
    "**Nota** que el iterador l comienza en 1 en el bucle for ya que los primeros parámetros son v[\"dW1\"] y v[\"db1\"] (eso es un \"uno\" en el superíndice).\n",
    "\n",
    "<details><summary>Code</summary>\n",
    "\n",
    "\n",
    "```python\n",
    "v[\"dW\" + str(l)] = np.zeros(parameters['W' + str(l)].shape)\n",
    "v[\"db\" + str(l)] = np.zeros(parameters['b' + str(l)].shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_velocity\n",
    "\n",
    "def initialize_velocity(parameters):\n",
    "    \"\"\"\n",
    "    Inicializa la velocidad como un diccionario python con\n",
    "                - llaves: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\" \n",
    "                - valores: matrices numpy de ceros de la misma forma que los gradientes/parámetros correspondientes.\n",
    "    Argumentos:\n",
    "    parámetros: diccionario python que contiene sus parámetros.\n",
    "                    parámetros['W' + str(l)] = Wl\n",
    "                    parámetros['b' + str(l)] = bl\n",
    "    \n",
    "    Devuelve:\n",
    "    v -- diccionario python que contiene la velocidad actual.\n",
    "                    v['dW' + str(l)] = velocidad de dWl\n",
    "                    v['db' + str(l)] = velocidad de dbl\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural networks\n",
    "    v = {}\n",
    "    \n",
    "    # Initialize velocity\n",
    "    for l in range(1, L + 1):\n",
    "        # (approx. 2 lines)\n",
    "        # v[\"dW\" + str(l)] =\n",
    "        # v[\"db\" + str(l)] =\n",
    "        # YOUR CODE STARTS HERE\n",
    "        \n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    "        \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = initialize_velocity_test_case()\n",
    "\n",
    "v = initialize_velocity(parameters)\n",
    "print(\"v[\\\"dW1\\\"] =\\n\" + str(v[\"dW1\"]))\n",
    "print(\"v[\\\"db1\\\"] =\\n\" + str(v[\"db1\"]))\n",
    "print(\"v[\\\"dW2\\\"] =\\n\" + str(v[\"dW2\"]))\n",
    "print(\"v[\\\"db2\\\"] =\\n\" + str(v[\"db2\"]))\n",
    "\n",
    "initialize_velocity_test(initialize_velocity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-4'></a>   \n",
    "### Ejercicio 4 - actualizar_parámetros_con_momento\n",
    "\n",
    "Ahora, implementa la actualización de los parámetros con el impulso. La regla de actualización del momento es, para $l = 1, ..., L$: \n",
    "\n",
    "$$ \\begin{cases}\n",
    "v_{dW^{[l]}} = \\beta v_{dW^{[l]}} + (1 - \\beta) dW^{[l]} \\\\\n",
    "W^{[l]} = W^{[l]} - \\alpha v_{dW^{[l]}}\n",
    "\\end{cases}\\tag{3}$$\n",
    "\n",
    "$$\\begin{cases}\n",
    "v_{db^{[l]}} = \\beta v_{db^{[l]}} + (1 - \\beta) db^{[l]} \\\\\n",
    "b^{[l]} = b^{[l]} - \\alpha v_{db^{[l]}} \n",
    "\\end{cases}\\tag{4}$$\n",
    "\n",
    "donde L es el número de capas, $\\beta$ es el impulso y $\\alpha$ es la tasa de aprendizaje. Todos los parámetros deben ser almacenados en el diccionario `parameters`.  Tenga en cuenta que el iterador `l` comienza en 1 en el bucle `for` ya que los primeros parámetros son $W^{[1]}$ y $b^{[1]}$ (eso es un \"uno\" en el superíndice).\n",
    "\n",
    "<details><summary>Code</summary>\n",
    "\n",
    "\n",
    "```pỳthon\n",
    "v[\"dW\" + str(l)] = beta * v[\"dW\" + str(l)] + (1 - beta) * grads['dW' + str(l)]\n",
    "v[\"db\" + str(l)] = beta * v[\"db\" + str(l)] + (1 - beta) * grads['db' + str(l)]\n",
    "# update parameters\n",
    "pameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate * v[\"dW\" + str(l)]\n",
    "parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate * v[\"db\" + str(l)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: update_parameters_with_momentum\n",
    "\n",
    "def update_parameters_with_momentum(parameters, grads, v, beta, learning_rate):\n",
    "    \"\"\"\n",
    "    Actualizar los parámetros utilizando el Momentum\n",
    "    \n",
    "    Argumentos:\n",
    "    parameters -- diccionario python que contiene sus parámetros:\n",
    "                    parameters['W' + str(l)] = Wl\n",
    "                    parameters['b' + str(l)] = bl\n",
    "    grads -- diccionario python que contiene sus gradientes para cada parámetro:\n",
    "                    grads['dW' + str(l)] = dWl\n",
    "                    grads['db' + str(l)] = dbl\n",
    "    v -- diccionario python que contiene la velocidad actual:\n",
    "                    v['dW' + str(l)] = ...\n",
    "                    v['db' + str(l)] = ...\n",
    "    beta -- el hiperparámetro del momento, escalar\n",
    "    learning_rate -- la tasa de aprendizaje, escalar\n",
    "    \n",
    "    Devuelve:\n",
    "    parameters -- diccionario python que contiene sus parámetros actualizados \n",
    "    v -- diccionario python que contiene sus velocidades actualizadas\n",
    "    \"\"\"\n",
    "\n",
    "    L = len(parameters) // 2 # number of layers in the neural networks\n",
    "    \n",
    "    # Momentum update for each parameter\n",
    "    for l in range(1, L + 1):\n",
    "        \n",
    "        # (approx. 4 lines)\n",
    "        # compute velocities\n",
    "        # v[\"dW\" + str(l)] = ...\n",
    "        # v[\"db\" + str(l)] = ...\n",
    "        # update parameters\n",
    "        # parameters[\"W\" + str(l)] = ...\n",
    "        # parameters[\"b\" + str(l)] = ...\n",
    "        # YOUR CODE STARTS HERE\n",
    "        \n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    "        \n",
    "    return parameters, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters, grads, v = update_parameters_with_momentum_test_case()\n",
    "\n",
    "parameters, v = update_parameters_with_momentum(parameters, grads, v, beta = 0.9, learning_rate = 0.01)\n",
    "print(\"W1 = \\n\" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \\n\" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \\n\" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \\n\" + str(parameters[\"b2\"]))\n",
    "print(\"v[\\\"dW1\\\"] = \\n\" + str(v[\"dW1\"]))\n",
    "print(\"v[\\\"db1\\\"] = \\n\" + str(v[\"db1\"]))\n",
    "print(\"v[\\\"dW2\\\"] = \\n\" + str(v[\"dW2\"]))\n",
    "print(\"v[\\\"db2\\\"] = v\" + str(v[\"db2\"]))\n",
    "\n",
    "update_parameters_with_momentum_test(update_parameters_with_momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota que**:\n",
    "- La velocidad se inicializa con ceros. Así que el algoritmo tomará algunas iteraciones para \"construir\" la velocidad y empezar a dar pasos más grandes.\n",
    "- Si $\\beta = 0$, entonces esto sólo se convierte en el descenso de gradiente estándar sin impulso. \n",
    "\n",
    "**¿Cómo se elige $\\beta$?\n",
    "\n",
    "- Cuanto más grande sea el momento $\\beta$, más suave será la actualización, porque tiene más en cuenta los gradientes pasados. Pero si $\\beta$ es demasiado grande, también podría suavizar demasiado las actualizaciones. \n",
    "- Los valores habituales de $\\beta$ van de 0,8 a 0,999. Si no se siente inclinado a ajustar esto, $\\beta = 0,9$ es a menudo un valor predeterminado razonable. \n",
    "- El ajuste de la $\\beta$ óptima para su modelo puede requerir probar varios valores para ver lo que funciona mejor en términos de reducir el valor de la función de coste $J$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "**Lo que debes recordar**:\n",
    "- El impulso tiene en cuenta los gradientes pasados para suavizar los pasos del descenso de gradiente. Se puede aplicar con el descenso de gradiente por lotes, el descenso de gradiente por mini lotes o el descenso de gradiente estocástico.\n",
    "- Hay que ajustar un hiperparámetro de impulso $\\beta$ y una tasa de aprendizaje $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5'></a>   \n",
    "## 5 - Adam\n",
    "\n",
    "Adam es uno de los algoritmos de optimización más eficaces para el entrenamiento de redes neuronales. Combina ideas de RMSProp (descrito en la conferencia) y Momentum. \n",
    "\n",
    "**¿Cómo funciona Adán?\n",
    "1. Calcula una media ponderada exponencialmente de los gradientes pasados, y la almacena en las variables $v$ (antes de la corrección del sesgo) y $v^{corregido}$ (con la corrección del sesgo). \n",
    "2. Calcula una media ponderada exponencialmente de los cuadrados de los gradientes pasados, y la almacena en las variables $s$ (antes de la corrección del sesgo) y $s^{corregida}$ (con la corrección del sesgo). \n",
    "3. Actualiza los parámetros en una dirección basada en la combinación de la información de \"1\" y \"2\".\n",
    "\n",
    "La regla de actualización es, para $l = 1, ..., L$: \n",
    "\n",
    "$$\\begin{cases}\n",
    "v_{dW^{[l]}} = \\beta_1 v_{dW^{[l]}} + (1 - \\beta_1) \\frac{\\partial \\mathcal{J} }{ \\partial W^{[l]} } \\\\\n",
    "v^{corrected}_{dW^{[l]}} = \\frac{v_{dW^{[l]}}}{1 - (\\beta_1)^t} \\\\\n",
    "s_{dW^{[l]}} = \\beta_2 s_{dW^{[l]}} + (1 - \\beta_2) (\\frac{\\partial \\mathcal{J} }{\\partial W^{[l]} })^2 \\\\\n",
    "s^{corrected}_{dW^{[l]}} = \\frac{s_{dW^{[l]}}}{1 - (\\beta_2)^t} \\\\\n",
    "W^{[l]} = W^{[l]} - \\alpha \\frac{v^{corrected}_{dW^{[l]}}}{\\sqrt{s^{corrected}_{dW^{[l]}}} + \\varepsilon}\n",
    "\\end{cases}$$\n",
    "donde\n",
    "- t cuenta el número de pasos dados de Adam \n",
    "- L es el número de capas\n",
    "- $\\beta_1$ y $\\beta_2$ son hiperparámetros que controlan las dos medias ponderadas exponencialmente \n",
    "- $\\alpha$ es la tasa de aprendizaje\n",
    "- $\\varepsilon$ es un número muy pequeño para evitar dividir por cero\n",
    "\n",
    "Como es habitual, todos los parámetros se almacenan en el diccionario `parámetros "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-5'></a>   \n",
    "### Ejercicio 5 - inicializar_adam\n",
    "\n",
    "Inicializar las variables Adam $v, s$ que guardan la información pasada.\n",
    "\n",
    "**Instrucción**: Las variables $v, s$ son diccionarios python que necesitan ser inicializados con matrices de ceros. Sus claves son las mismas que para `grads`, es decir\n",
    "para $l = 1, ..., L$:\n",
    "\n",
    "```python\n",
    "v[\"dW\" + str(l)] = ... #(numpy array of zeros with the same shape as parameters[\"W\" + str(l)])\n",
    "v[\"db\" + str(l)] = ... #(numpy array of zeros with the same shape as parameters[\"b\" + str(l)])\n",
    "s[\"dW\" + str(l)] = ... #(numpy array of zeros with the same shape as parameters[\"W\" + str(l)])\n",
    "s[\"db\" + str(l)] = ... #(numpy array of zeros with the same shape as parameters[\"b\" + str(l)])\n",
    "\n",
    "```\n",
    "\n",
    "<details><summary>Code</summary>\n",
    "\n",
    "\n",
    "```python\n",
    " \n",
    "v[\"dW\" + str(l)] = np.zeros(parameters['W' + str(l)].shape)\n",
    "v[\"db\" + str(l)] = np.zeros(parameters['b' + str(l)].shape)\n",
    "s[\"dW\" + str(l)] = np.zeros(parameters['W' + str(l)].shape)\n",
    "s[\"db\" + str(l)] = np.zeros(parameters['b' + str(l)].shape)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_adam\n",
    "\n",
    "def initialize_adam(parameters) :\n",
    "    \"\"\"\n",
    "    Inicializa v y s como dos diccionarios python con:\n",
    "                - llaves: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\" \n",
    "                - valores: matrices numpy de ceros de la misma forma que los gradientes/parámetros correspondientes.\n",
    "    \n",
    "    Argumentos:\n",
    "    parámetros: diccionario python que contiene sus parámetros.\n",
    "                    parámetros[\"W\" + str(l)] = Wl\n",
    "                    parameters[\"b\" + str(l)] = bl\n",
    "    \n",
    "    Devuelve: \n",
    "    v -- diccionario de python que contendrá la media ponderada exponencialmente del gradiente. Inicializado con ceros.\n",
    "                    v[\"dW\" + str(l)] = ...\n",
    "                    v[\"db\" + str(l)] = ...\n",
    "    s -- diccionario python que contendrá la media ponderada exponencialmente del gradiente al cuadrado. Inicializado con ceros.\n",
    "                    s[\"dW\" + str(l)] = ...\n",
    "                    s[\"db\" + str(l)] = ...\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural networks\n",
    "    v = {}\n",
    "    s = {}\n",
    "    \n",
    "    # Initialize v, s. Input: \"parameters\". Outputs: \"v, s\".\n",
    "    for l in range(1, L + 1):\n",
    "    # (approx. 4 lines)\n",
    "        # v[\"dW\" + str(l)] = ...\n",
    "        # v[\"db\" + str(l)] = ...\n",
    "        # s[\"dW\" + str(l)] = ...\n",
    "        # s[\"db\" + str(l)] = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    return v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = initialize_adam_test_case()\n",
    "\n",
    "v, s = initialize_adam(parameters)\n",
    "print(\"v[\\\"dW1\\\"] = \\n\" + str(v[\"dW1\"]))\n",
    "print(\"v[\\\"db1\\\"] = \\n\" + str(v[\"db1\"]))\n",
    "print(\"v[\\\"dW2\\\"] = \\n\" + str(v[\"dW2\"]))\n",
    "print(\"v[\\\"db2\\\"] = \\n\" + str(v[\"db2\"]))\n",
    "print(\"s[\\\"dW1\\\"] = \\n\" + str(s[\"dW1\"]))\n",
    "print(\"s[\\\"db1\\\"] = \\n\" + str(s[\"db1\"]))\n",
    "print(\"s[\\\"dW2\\\"] = \\n\" + str(s[\"dW2\"]))\n",
    "print(\"s[\\\"db2\\\"] = \\n\" + str(s[\"db2\"]))\n",
    "\n",
    "initialize_adam_test(initialize_adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-6'></a>   \n",
    "### Ejercicio 6 - update_parameters_with_adam\n",
    "\n",
    "Ahora, implementa la actualización de parámetros con Adam. Recuerda que la regla general de actualización es, para $l = 1, ..., L$: \n",
    "\n",
    "$$\\begin{cases}\n",
    "v_{dW^{[l]}} = \\beta_1 v_{dW^{[l]}} + (1 - \\beta_1) \\frac{\\partial \\mathcal{J} }{ \\partial W^{[l]} } \\\\\n",
    "v^{corrected}_{dW^{[l]}} = \\frac{v_{dW^{[l]}}}{1 - (\\beta_1)^t} \\\\\n",
    "s_{dW^{[l]}} = \\beta_2 s_{dW^{[l]}} + (1 - \\beta_2) (\\frac{\\partial \\mathcal{J} }{\\partial W^{[l]} })^2 \\\\\n",
    "s^{corrected}_{dW^{[l]}} = \\frac{s_{dW^{[l]}}}{1 - (\\beta_2)^t} \\\\\n",
    "W^{[l]} = W^{[l]} - \\alpha \\frac{v^{corrected}_{dW^{[l]}}}{\\sqrt{s^{corrected}_{dW^{[l]}}} + \\varepsilon}\n",
    "\\end{cases}$$\n",
    "\n",
    "**Nótese** que el iterador `l` comienza en 1 en el bucle `for` ya que los primeros parámetros son $W^{[1]}$ y $b^{[1]}$. \n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "for l in range(1, L + 1):\n",
    " \n",
    "        v[\"dW\" + str(l)] = beta1 * v[\"dW\" + str(l)] + (1 - beta1) * grads['dW' + str(l)]\n",
    "        v[\"db\" + str(l)] = beta1 * v[\"db\" + str(l)] + (1 - beta1) * grads['db' + str(l)]\n",
    "        \n",
    "        v_corrected[\"dW\" + str(l)] = v[\"dW\" + str(l)] / (1 - np.power(beta1, t))\n",
    "        v_corrected[\"db\" + str(l)] = v[\"db\" + str(l)] / (1 - np.power(beta1, t))\n",
    "        \n",
    "        s[\"dW\" + str(l)] = beta2 * s[\"dW\" + str(l)] + (1 - beta2) * np.power(grads['dW' + str(l)], 2)\n",
    "        s[\"db\" + str(l)] = beta2 * s[\"db\" + str(l)] + (1 - beta2) * np.power(grads['db' + str(l)], 2)\n",
    "        \n",
    "        s_corrected[\"dW\" + str(l)] = s[\"dW\" + str(l)] / (1 - np.power(beta2, t))\n",
    "        s_corrected[\"db\" + str(l)] = s[\"db\" + str(l)] / (1 - np.power(beta2, t))\n",
    "        \n",
    "        parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate * v_corrected[\"dW\" + str(l)] / (np.sqrt(s_corrected[\"dW\" + str(l)]) + epsilon)\n",
    "        parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate * v_corrected[\"db\" + str(l)] / (np.sqrt(s_corrected[\"db\" + str(l)]) + epsilon)\n",
    "        \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: update_parameters_with_adam\n",
    "\n",
    "def update_parameters_with_adam(parameters, grads, v, s, t, learning_rate = 0.01,\n",
    "                                beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8):\n",
    "    \"\"\"\n",
    "    Actualizar parámetros con Adam\n",
    "    \n",
    "    Argumentos:\n",
    "    parameters -- diccionario python que contiene sus parámetros:\n",
    "                    parámetros['W' + str(l)] = Wl\n",
    "                    parameters['b' + str(l)] = bl\n",
    "    grads -- diccionario python que contiene sus gradientes para cada parámetro:\n",
    "                    grads['dW' + str(l)] = dWl\n",
    "                    grads['db' + str(l)] = dbl\n",
    "    v -- Variable Adam, media móvil del primer gradiente, diccionario python\n",
    "    s -- Variable Adam, media móvil del gradiente al cuadrado, diccionario python\n",
    "    t -- Variable de Adam, cuenta el número de pasos tomados\n",
    "    learning_rate -- la tasa de aprendizaje, escalar.\n",
    "    beta1 -- Hiperparámetro de decaimiento exponencial para las estimaciones del primer momento \n",
    "    beta2 -- Hiperparámetro de decaimiento exponencial para las estimaciones del segundo momento \n",
    "    epsilon -- hiperparámetro que evita la división por cero en las actualizaciones de Adam\n",
    "\n",
    "    Devuelve:\n",
    "    parameters -- diccionario python que contiene sus parámetros actualizados \n",
    "    v -- Variable Adam, media móvil del primer gradiente, diccionario python\n",
    "    s -- Variable Adam, media móvil del gradiente al cuadrado, diccionario python\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2                 # number of layers in the neural networks\n",
    "    v_corrected = {}                         # Initializing first moment estimate, python dictionary\n",
    "    s_corrected = {}                         # Initializing second moment estimate, python dictionary\n",
    "    \n",
    "    # Perform Adam update on all parameters\n",
    "    for l in range(1, L + 1):\n",
    "        # Moving average of the gradients. Inputs: \"v, grads, beta1\". Output: \"v\".\n",
    "        # (approx. 2 lines)\n",
    "        # v[\"dW\" + str(l)] = ...\n",
    "        # v[\"db\" + str(l)] = ...\n",
    "        # YOUR CODE STARTS HERE\n",
    "        \n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    "\n",
    "        # Compute bias-corrected first moment estimate. Inputs: \"v, beta1, t\". Output: \"v_corrected\".\n",
    "        # (approx. 2 lines)\n",
    "        # v_corrected[\"dW\" + str(l)] = ...\n",
    "        # v_corrected[\"db\" + str(l)] = ...\n",
    "        # YOUR CODE STARTS HERE\n",
    "        \n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    "\n",
    "        # Moving average of the squared gradients. Inputs: \"s, grads, beta2\". Output: \"s\".\n",
    "        #(approx. 2 lines)\n",
    "        # s[\"dW\" + str(l)] = ...\n",
    "        # s[\"db\" + str(l)] = ...\n",
    "        # YOUR CODE STARTS HERE\n",
    "        \n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    "\n",
    "        # Compute bias-corrected second raw moment estimate. Inputs: \"s, beta2, t\". Output: \"s_corrected\".\n",
    "        # (approx. 2 lines)\n",
    "        # s_corrected[\"dW\" + str(l)] = ...\n",
    "        # s_corrected[\"db\" + str(l)] = ...\n",
    "        # YOUR CODE STARTS HERE\n",
    "        \n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    "\n",
    "        # Update parameters. Inputs: \"parameters, learning_rate, v_corrected, s_corrected, epsilon\". Output: \"parameters\".\n",
    "        # (approx. 2 lines)\n",
    "        # parameters[\"W\" + str(l)] = ...\n",
    "        # parameters[\"b\" + str(l)] = ...\n",
    "        # YOUR CODE STARTS HERE\n",
    "        \n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    "\n",
    "    return parameters, v, s, v_corrected, s_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametersi, grads, vi, si, t, learning_rate, beta1, beta2, epsilon = update_parameters_with_adam_test_case()\n",
    "\n",
    "parameters, v, s, vc, sc  = update_parameters_with_adam(parametersi, grads, vi, si, t, learning_rate, beta1, beta2, epsilon)\n",
    "print(f\"W1 = \\n{parameters['W1']}\")\n",
    "print(f\"W2 = \\n{parameters['W2']}\")\n",
    "print(f\"b1 = \\n{parameters['b1']}\")\n",
    "print(f\"b2 = \\n{parameters['b2']}\")\n",
    "\n",
    "update_parameters_with_adam_test(update_parameters_with_adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tiene tres algoritmos de optimización que funcionan (descenso de gradiente por lotes, Momentum, Adam). Implementemos un modelo con cada uno de estos optimizadores y observemos la diferencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='6'></a>  \n",
    "## 6 - Modelo con diferentes algoritmos de optimización\n",
    "\n",
    "A continuación, utilizará el siguiente conjunto de datos \"lunas\" para probar los diferentes métodos de optimización. (El conjunto de datos se llama \"lunas\" porque los datos de cada una de las dos clases se parecen un poco a una luna en forma de media luna). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, layers_dims, optimizer, learning_rate = 0.0007, mini_batch_size = 64, beta = 0.9,\n",
    "          beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, num_epochs = 5000, print_cost = True):\n",
    "    \"\"\"\n",
    "    Modelo de red neuronal de 3 capas que se puede ejecutar en diferentes modos de optimización.\n",
    "    \n",
    "    Argumentos:\n",
    "    X -- datos de entrada, de forma (2, número de ejemplos)\n",
    "    Y -- verdadero vector de \"etiqueta\" (1 para punto azul / 0 para punto rojo), de forma (1, número de ejemplos)\n",
    "    optimizador: el optimizador que se debe pasar, descenso de gradiente, impulso o adam\n",
    "    layers_dims -- lista de python, que contiene el tamaño de cada capa\n",
    "    learning_rate -- la tasa de aprendizaje, escalar.\n",
    "    mini_batch_size: el tamaño de un mini lote\n",
    "    beta -- Hiperparámetro de momento\n",
    "    beta1: hiperparámetro de decaimiento exponencial para las estimaciones de gradientes anteriores\n",
    "    beta2: hiperparámetro de decaimiento exponencial para las estimaciones de gradientes cuadrados anteriores\n",
    "    epsilon: hiperparámetro que evita la división por cero en las actualizaciones de Adam\n",
    "    num_epochs -- número de épocas\n",
    "    print_cost -- True para imprimir el costo cada 1000 épocas\n",
    "\n",
    "    Devoluciones:\n",
    "    parámetros -- diccionario de python que contiene sus parámetros actualizados\n",
    "    \"\"\"\n",
    "\n",
    "    L = len(layers_dims)             # number of layers in the neural networks\n",
    "    costs = []                       # to keep track of the cost\n",
    "    t = 0                            # initializing the counter required for Adam update\n",
    "    seed = 10                        # For grading purposes, so that your \"random\" minibatches are the same as ours\n",
    "    m = X.shape[1]                   # number of training examples\n",
    "    \n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters(layers_dims)\n",
    "\n",
    "    # Initialize the optimizer\n",
    "    if optimizer == \"gd\":\n",
    "        pass # no initialization required for gradient descent\n",
    "    elif optimizer == \"momentum\":\n",
    "        v = initialize_velocity(parameters)\n",
    "    elif optimizer == \"adam\":\n",
    "        v, s = initialize_adam(parameters)\n",
    "    \n",
    "    # Optimization loop\n",
    "    for i in range(num_epochs):\n",
    "        \n",
    "        # Define the random minibatches. We increment the seed to reshuffle differently the dataset after each epoch\n",
    "        seed = seed + 1\n",
    "        minibatches = random_mini_batches(X, Y, mini_batch_size, seed)\n",
    "        cost_total = 0\n",
    "        \n",
    "        for minibatch in minibatches:\n",
    "\n",
    "            # Select a minibatch\n",
    "            (minibatch_X, minibatch_Y) = minibatch\n",
    "\n",
    "            # Forward propagation\n",
    "            a3, caches = forward_propagation(minibatch_X, parameters)\n",
    "\n",
    "            # Compute cost and add to the cost total\n",
    "            cost_total += compute_cost(a3, minibatch_Y)\n",
    "\n",
    "            # Backward propagation\n",
    "            grads = backward_propagation(minibatch_X, minibatch_Y, caches)\n",
    "\n",
    "            # Update parameters\n",
    "            if optimizer == \"gd\":\n",
    "                parameters = update_parameters_with_gd(parameters, grads, learning_rate)\n",
    "            elif optimizer == \"momentum\":\n",
    "                parameters, v = update_parameters_with_momentum(parameters, grads, v, beta, learning_rate)\n",
    "            elif optimizer == \"adam\":\n",
    "                t = t + 1 # Adam counter\n",
    "                parameters, v, s, _, _ = update_parameters_with_adam(parameters, grads, v, s,\n",
    "                                                               t, learning_rate, beta1, beta2,  epsilon)\n",
    "        cost_avg = cost_total / m\n",
    "        \n",
    "        # Print the cost every 1000 epoch\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (\"Cost after epoch %i: %f\" %(i, cost_avg))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost_avg)\n",
    "                \n",
    "    # plot the cost\n",
    "    plt.plot(costs)\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('epochs (per 100)')\n",
    "    plt.title(\"Learning rate = \" + str(learning_rate))\n",
    "    plt.show()\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, ejecuta esta red neuronal de 3 capas con cada uno de los 3 métodos de optimización.\n",
    "\n",
    "<a name='6-1'></a>  \n",
    "### 6.1 - Mini-Batch Gradient Descent\n",
    "\n",
    "Ejecuta el siguiente código para ver cómo se comporta el modelo con el descenso de gradiente en mini lotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 3-layer model\n",
    "layers_dims = [train_X.shape[0], 5, 2, 1]\n",
    "parameters = model(train_X, train_Y, layers_dims, optimizer = \"gd\")\n",
    "\n",
    "# Predict\n",
    "predictions = predict(train_X, train_Y, parameters)\n",
    "\n",
    "# Plot decision boundary\n",
    "plt.title(\"Model with Gradient Descent optimization\")\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-1.5,2.5])\n",
    "axes.set_ylim([-1,1.5])\n",
    "plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='6-2'></a>  \n",
    "### 6.2 - Descenso de gradiente en miniatura con impulso\n",
    "\n",
    "A continuación, ejecute el siguiente código para ver cómo funciona el modelo con momentum. Debido a que este ejemplo es relativamente simple, las ganancias de usar momemtum son pequeñas - pero para problemas más complejos podría ver ganancias mayores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 3-layer model\n",
    "layers_dims = [train_X.shape[0], 5, 2, 1]\n",
    "parameters = model(train_X, train_Y, layers_dims, beta = 0.9, optimizer = \"momentum\")\n",
    "\n",
    "# Predict\n",
    "predictions = predict(train_X, train_Y, parameters)\n",
    "\n",
    "# Plot decision boundary\n",
    "plt.title(\"Model with Momentum optimization\")\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-1.5,2.5])\n",
    "axes.set_ylim([-1,1.5])\n",
    "plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='6-3'></a>  \n",
    "### 6.3 - Minilotes con Adam\n",
    "\n",
    "Por último, ejecuta el siguiente código para ver cómo funciona el modelo con Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 3-layer model\n",
    "layers_dims = [train_X.shape[0], 5, 2, 1]\n",
    "parameters = model(train_X, train_Y, layers_dims, optimizer = \"adam\")\n",
    "\n",
    "# Predict\n",
    "predictions = predict(train_X, train_Y, parameters)\n",
    "\n",
    "# Plot decision boundary\n",
    "plt.title(\"Model with Adam optimization\")\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-1.5,2.5])\n",
    "axes.set_ylim([-1,1.5])\n",
    "plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='6-4'></a>  \n",
    "### 6.4 - Summary\n",
    "\n",
    "<table> \n",
    "    <tr>\n",
    "        <td>\n",
    "        <b>método de optimización</b>\n",
    "        </td>\n",
    "        <td>\n",
    "        <b>accuracy</b>\n",
    "        </td>\n",
    "        <td>\n",
    "        <b>cost shape</b>\n",
    "        </td>\n",
    "    </tr>\n",
    "        <td>\n",
    "        Gradient descent\n",
    "        </td>\n",
    "        <td>\n",
    "        >71%\n",
    "        </td>\n",
    "        <td>\n",
    "        smooth\n",
    "        </td>\n",
    "    <tr>\n",
    "        <td>\n",
    "        Momentum\n",
    "        </td>\n",
    "        <td>\n",
    "        >71%\n",
    "        </td>\n",
    "        <td>\n",
    "        smooth\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "        Adam\n",
    "        </td>\n",
    "        <td>\n",
    "        >94%\n",
    "        </td>\n",
    "        <td>\n",
    "        smoother\n",
    "        </td>\n",
    "    </tr>\n",
    "</table> \n",
    "\n",
    "Momentum suele ayudar, pero dada la pequeña tasa de aprendizaje y el conjunto de datos simplista, su impacto es casi insignificante.\n",
    "\n",
    "Por otro lado, Adam supera claramente al descenso de gradiente por lotes y a Momentum. Si se ejecuta el modelo durante más épocas en este sencillo conjunto de datos, los tres métodos darán muy buenos resultados. Sin embargo, se ha visto que Adam converge mucho más rápido.\n",
    "\n",
    "Algunas de las ventajas de Adam son\n",
    "\n",
    "- Requiere relativamente poca memoria (aunque es mayor que el descenso por gradiente y el descenso por gradiente con impulso) \n",
    "- Suele funcionar bien incluso con poco ajuste de los hiperparámetros (excepto $\\alpha$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referencias**:\n",
    "\n",
    "- Documento de Adam: https://arxiv.org/pdf/1412.6980.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='7'></a>  \n",
    "## 7 - Decaimiento de la tasa de aprendizaje y programación\n",
    "\n",
    "Por último, la tasa de aprendizaje es otro hiperparámetro que puede ayudarle a acelerar el aprendizaje. \n",
    "\n",
    "Durante la primera parte del entrenamiento, su modelo puede salirse con la suya dando grandes pasos, pero con el tiempo, el uso de un valor fijo para la tasa de aprendizaje alfa puede hacer que su modelo se quede atascado en una amplia oscilación que nunca llega a converger. Pero si redujera lentamente su tasa de aprendizaje alfa a lo largo del tiempo, podría dar pasos más pequeños y lentos que le acercaran al mínimo. Esta es la idea que subyace a la disminución de la tasa de aprendizaje. \n",
    "\n",
    "La disminución de la tasa de aprendizaje puede lograrse utilizando métodos adaptativos o programas de tasa de aprendizaje predefinidos. \n",
    "\n",
    "Ahora, aplicaremos la disminución programada de la tasa de aprendizaje a una red neuronal de 3 capas en tres modos diferentes del optimizador y veremos cómo difiere cada uno, así como el efecto de la programación en diferentes épocas. \n",
    "\n",
    "Este modelo es esencialmente el mismo que usaste antes, excepto que en este podrás incluir el decaimiento de la tasa de aprendizaje. Incluye dos nuevos parámetros, decay y decay_rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, layers_dims, optimizer, learning_rate = 0.0007, mini_batch_size = 64, beta = 0.9,\n",
    "          beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, num_epochs = 5000, print_cost = True, decay=None, decay_rate=1):\n",
    "    \"\"\"\n",
    "    Modelo de red neuronal de 3 capas que puede ejecutarse en diferentes modos de optimización.\n",
    "    \n",
    "    Argumentos:\n",
    "    X -- datos de entrada, de forma (2, número de ejemplos)\n",
    "    Y -- vector \"etiqueta\" verdadera (1 para el punto azul / 0 para el punto rojo), de forma (1, número de ejemplos)\n",
    "    layers_dims -- lista de python, que contiene el tamaño de cada capa\n",
    "    learning_rate -- la tasa de aprendizaje, escalar.\n",
    "    mini_batch_size -- el tamaño de un mini lote\n",
    "    beta -- Hiperparámetro de impulso\n",
    "    beta1 -- Hiperparámetro de decaimiento exponencial para las estimaciones de los gradientes pasados \n",
    "    beta2 -- Hiperparámetro de decaimiento exponencial para las estimaciones de gradientes pasados al cuadrado \n",
    "    epsilon -- hiperparámetro que evita la división por cero en las actualizaciones de Adam\n",
    "    num_epochs -- número de épocas\n",
    "    print_cost -- Verdadero para imprimir el coste cada 1000 épocas\n",
    "\n",
    "    Devuelve:\n",
    "    parameters -- diccionario python que contiene sus parámetros actualizados \n",
    "    \"\"\"\n",
    "\n",
    "    L = len(layers_dims)             # number of layers in the neural networks\n",
    "    costs = []                       # to keep track of the cost\n",
    "    t = 0                            # initializing the counter required for Adam update\n",
    "    seed = 10                        # For grading purposes, so that your \"random\" minibatches are the same as ours\n",
    "    m = X.shape[1]                   # number of training examples\n",
    "    lr_rates = []\n",
    "    learning_rate0 = learning_rate   # the original learning rate\n",
    "    \n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters(layers_dims)\n",
    "\n",
    "    # Initialize the optimizer\n",
    "    if optimizer == \"gd\":\n",
    "        pass # no initialization required for gradient descent\n",
    "    elif optimizer == \"momentum\":\n",
    "        v = initialize_velocity(parameters)\n",
    "    elif optimizer == \"adam\":\n",
    "        v, s = initialize_adam(parameters)\n",
    "    \n",
    "    # Optimization loop\n",
    "    for i in range(num_epochs):\n",
    "        \n",
    "        # Define the random minibatches. We increment the seed to reshuffle differently the dataset after each epoch\n",
    "        seed = seed + 1\n",
    "        minibatches = random_mini_batches(X, Y, mini_batch_size, seed)\n",
    "        cost_total = 0\n",
    "        \n",
    "        for minibatch in minibatches:\n",
    "\n",
    "            # Select a minibatch\n",
    "            (minibatch_X, minibatch_Y) = minibatch\n",
    "\n",
    "            # Forward propagation\n",
    "            a3, caches = forward_propagation(minibatch_X, parameters)\n",
    "\n",
    "            # Compute cost and add to the cost total\n",
    "            cost_total += compute_cost(a3, minibatch_Y)\n",
    "\n",
    "            # Backward propagation\n",
    "            grads = backward_propagation(minibatch_X, minibatch_Y, caches)\n",
    "\n",
    "            # Update parameters\n",
    "            if optimizer == \"gd\":\n",
    "                parameters = update_parameters_with_gd(parameters, grads, learning_rate)\n",
    "            elif optimizer == \"momentum\":\n",
    "                parameters, v = update_parameters_with_momentum(parameters, grads, v, beta, learning_rate)\n",
    "            elif optimizer == \"adam\":\n",
    "                t = t + 1 # Adam counter\n",
    "                parameters, v, s, _, _ = update_parameters_with_adam(parameters, grads, v, s,\n",
    "                                                               t, learning_rate, beta1, beta2,  epsilon)\n",
    "        cost_avg = cost_total / m\n",
    "        if decay:\n",
    "            learning_rate = decay(learning_rate0, i, decay_rate)\n",
    "        # Print the cost every 1000 epoch\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (\"Cost after epoch %i: %f\" %(i, cost_avg))\n",
    "            if decay:\n",
    "                print(\"learning rate after epoch %i: %f\"%(i, learning_rate))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost_avg)\n",
    "                \n",
    "    # plot the cost\n",
    "    plt.plot(costs)\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('epochs (per 100)')\n",
    "    plt.title(\"Learning rate = \" + str(learning_rate))\n",
    "    plt.show()\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='7-1'></a>  \n",
    "### 7.1 - Decay on every iteration  \n",
    "\n",
    "Para esta parte de la tarea, probarás uno de los programas predefinidos para el decaimiento de la tasa de aprendizaje, llamado decaimiento exponencial de la tasa de aprendizaje. Tiene esta forma matemática:\n",
    "\n",
    "$$\\alpha = \\frac{1}{1 + decayRate \\times epochNumber} \\alpha_{0}$$\n",
    "\n",
    "<a name='ex-7'></a>  \n",
    "### Exercise 7 - update_lr\n",
    "\n",
    "Calcular la nueva tasa de aprendizaje utilizando el decaimiento exponencial del peso.\n",
    "\n",
    "<details><summary>Code</summary>\n",
    "\n",
    "\n",
    "```python\n",
    "learning_rate = learning_rate0 / (1 + decay_rate * epoch_num)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: update_lr\n",
    "\n",
    "def update_lr(learning_rate0, epoch_num, decay_rate):\n",
    "    \"\"\"\n",
    "    Calculates updated the learning rate using exponential weight decay.\n",
    "    \n",
    "    Arguments:\n",
    "    learning_rate0 -- Original learning rate. Scalar\n",
    "    epoch_num -- Epoch number. Integer\n",
    "    decay_rate -- Decay rate. Scalar\n",
    "\n",
    "    Returns:\n",
    "    learning_rate -- Updated learning rate. Scalar \n",
    "    \"\"\"\n",
    "    #(approx. 1 line)\n",
    "    # learning_rate = \n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    \n",
    "    # YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.5\n",
    "print(\"Original learning rate: \", learning_rate)\n",
    "epoch_num = 2\n",
    "decay_rate = 1\n",
    "learning_rate_2 = update_lr(learning_rate, epoch_num, decay_rate)\n",
    "\n",
    "print(\"Updated learning rate: \", learning_rate_2)\n",
    "\n",
    "update_lr_test(update_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 3-layer model\n",
    "layers_dims = [train_X.shape[0], 5, 2, 1]\n",
    "parameters = model(train_X, train_Y, layers_dims, optimizer = \"gd\", learning_rate = 0.1, num_epochs=5000, decay=update_lr)\n",
    "\n",
    "# Predict\n",
    "predictions = predict(train_X, train_Y, parameters)\n",
    "\n",
    "# Plot decision boundary\n",
    "plt.title(\"Model with Gradient Descent optimization\")\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-1.5,2.5])\n",
    "axes.set_ylim([-1,1.5])\n",
    "plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que si configura el decaimiento para que se produzca en cada iteración, la tasa de aprendizaje llega a cero demasiado rápido, incluso si comienza con una tasa de aprendizaje más alta. \n",
    "<table> \n",
    "    <tr>\n",
    "        <td>\n",
    "        <b>Epoch Number</b>\n",
    "        </td>\n",
    "        <td>\n",
    "        <b>Learning Rate</b>\n",
    "        </td>\n",
    "        <td>\n",
    "        <b>Cost</b>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "        0\n",
    "        </td>\n",
    "        <td>\n",
    "        0.100000\n",
    "        </td>\n",
    "        <td>\n",
    "        0.701091\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "        1000\n",
    "        </td>\n",
    "        <td>\n",
    "        0.000100\n",
    "        </td>\n",
    "        <td>\n",
    "        0.661884\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "        2000\n",
    "        </td>\n",
    "        <td>\n",
    "        0.000050\n",
    "        </td>\n",
    "        <td>\n",
    "        0.658620\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "        3000\n",
    "        </td>\n",
    "        <td>\n",
    "        0.000033\n",
    "        </td>\n",
    "        <td>\n",
    "        0.656765\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "        4000\n",
    "        </td>\n",
    "        <td>\n",
    "        0.000025\n",
    "        </td>\n",
    "        <td>\n",
    "        0.655486\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "        5000\n",
    "        </td>\n",
    "        <td>\n",
    "        0.000020\n",
    "        </td>\n",
    "        <td>\n",
    "        0.654514\n",
    "        </td>\n",
    "    </tr>\n",
    "</table> \n",
    "\n",
    "Cuando se entrena durante unas pocas épocas esto no causa muchos problemas, pero cuando el número de épocas es grande el algoritmo de optimización dejará de actualizarse. Una solución común a este problema es decaer la tasa de aprendizaje cada pocos pasos. Esto se llama programación a intervalos fijos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a name='7-2'></a> \n",
    "### 7.2 - Programación a intervalos fijos\n",
    "\n",
    "Puede evitar que la velocidad de aprendizaje llegue a cero demasiado rápido programando el decaimiento de la velocidad de aprendizaje exponencial en un intervalo de tiempo fijo, por ejemplo 1000. Puede numerar los intervalos, o dividir la época por el intervalo de tiempo, que es el tamaño de la ventana con la tasa de aprendizaje constante. \n",
    "\n",
    "<img src=\"images/lr.png\" style=\"width:400px;height:250px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-8'></a> \n",
    "### Ejercicio 8 - schedule_lr_decay\n",
    "\n",
    "Calcule la nueva tasa de aprendizaje utilizando el decaimiento exponencial del peso con la programación de intervalos fijos.\n",
    "\n",
    "**Instrucciones**: Implementar la programación de la tasa de aprendizaje de manera que sólo cambie cuando el epochNum sea un múltiplo del timeInterval.\n",
    "\n",
    "**Nota:** La fracción en el denominador utiliza la operación suelo. \n",
    "\n",
    "$$\\alpha = \\frac{1}{1 + decayRate \\times \\lfloor\\frac{epochNum}{timeInterval}\\rfloor} \\alpha_{0}$$\n",
    "\n",
    "**Hint:** [numpy.floor](https://numpy.org/doc/stable/reference/generated/numpy.floor.html)\n",
    "\n",
    "<details><summary>Code</summary>\n",
    "\n",
    "\n",
    "```python\n",
    "learning_rate = learning_rate0 / (1 + decay_rate * np.floor(epoch_num / time_interval))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: schedule_lr_decay\n",
    "\n",
    "def schedule_lr_decay(learning_rate0, epoch_num, decay_rate, time_interval=1000):\n",
    "    \"\"\"\n",
    "    Calcula la tasa de aprendizaje actualizada utilizando el decaimiento exponencial del peso.\n",
    "    \n",
    "    Argumentos:\n",
    "    learning_rate0 -- Tasa de aprendizaje original. Escalar\n",
    "    epoch_num -- Número de época. Entero.\n",
    "    decay_rate -- Tasa de decaimiento. Scalar.\n",
    "    time_interval -- Número de épocas en las que se actualiza la tasa de aprendizaje.\n",
    "\n",
    "    Devuelve:\n",
    "    learning_rate -- Tasa de aprendizaje actualizada. Escalar \n",
    "    \"\"\"\n",
    "    # (approx. 1 lines)\n",
    "    # learning_rate = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    return learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**\n",
    "```\n",
    "Original learning rate:  0.5\n",
    "Updated learning rate after 10 epochs:  0.5\n",
    "Updated learning rate after 100 epochs:  0.3846153846153846\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='7-3'></a> \n",
    "### 7.3 - Utilizar el decaimiento de la tasa de aprendizaje para cada método de optimización\n",
    "\n",
    "A continuación, utilizará el siguiente conjunto de datos \"lunas\" para probar los diferentes métodos de optimización. (El conjunto de datos se llama \"lunas\" porque los datos de cada una de las dos clases se parecen un poco a una luna en forma de media luna). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='7-3-1'></a> \n",
    "#### 7.3.1 - Descenso de gradiente con decaimiento de la tasa de aprendizaje\n",
    "\n",
    "Ejecute el siguiente código para ver cómo el modelo realiza el descenso de gradiente y el decaimiento del peso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 3-layer model\n",
    "layers_dims = [train_X.shape[0], 5, 2, 1]\n",
    "parameters = model(train_X, train_Y, layers_dims, optimizer = \"gd\", learning_rate = 0.1, num_epochs=5000, decay=schedule_lr_decay)\n",
    "\n",
    "# Predict\n",
    "predictions = predict(train_X, train_Y, parameters)\n",
    "\n",
    "# Plot decision boundary\n",
    "plt.title(\"Model with Gradient Descent optimization\")\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-1.5,2.5])\n",
    "axes.set_ylim([-1,1.5])\n",
    "plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='7-3-2'></a> \n",
    "#### 7.3.2 - Descenso de gradiente con decaimiento del momento y de la tasa de aprendizaje\n",
    "\n",
    "Ejecute el siguiente código para ver cómo el modelo realiza el descenso de gradiente con impulso y decaimiento de peso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 3-layer model\n",
    "layers_dims = [train_X.shape[0], 5, 2, 1]\n",
    "parameters = model(train_X, train_Y, layers_dims, optimizer = \"momentum\", learning_rate = 0.1, num_epochs=5000, decay=schedule_lr_decay)\n",
    "\n",
    "# Predict\n",
    "predictions = predict(train_X, train_Y, parameters)\n",
    "\n",
    "# Plot decision boundary\n",
    "plt.title(\"Model with Gradient Descent with momentum optimization\")\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-1.5,2.5])\n",
    "axes.set_ylim([-1,1.5])\n",
    "plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='7-3-3'></a> \n",
    "#### 7.3.3 - Adán con decaimiento de la tasa de aprendizaje\n",
    "\n",
    "Ejecute el siguiente código para ver cómo el modelo hace Adán y el decaimiento del peso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 3-layer model\n",
    "layers_dims = [train_X.shape[0], 5, 2, 1]\n",
    "parameters = model(train_X, train_Y, layers_dims, optimizer = \"adam\", learning_rate = 0.01, num_epochs=5000, decay=schedule_lr_decay)\n",
    "\n",
    "# Predict\n",
    "predictions = predict(train_X, train_Y, parameters)\n",
    "\n",
    "# Plot decision boundary\n",
    "plt.title(\"Model with Adam optimization\")\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-1.5,2.5])\n",
    "axes.set_ylim([-1,1.5])\n",
    "plot_decision_boundary(lambda x: predict_dec(parameters, x.T), train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='7-4'></a> \n",
    "### 7.4 - Lograr un rendimiento similar con diferentes métodos\n",
    "\n",
    "Con Mini-batch GD o Mini-batch GD con Momentum, la precisión es significativamente inferior a la de Adam, pero cuando se añade el decaimiento de la tasa de aprendizaje, cualquiera de los dos puede lograr un rendimiento a una velocidad y una puntuación de precisión similares a las de Adam.\n",
    "\n",
    "En el caso de Adam, observe que la curva de aprendizaje alcanza una precisión similar pero más rápida.\n",
    "\n",
    "<table> \n",
    "    <tr>\n",
    "        <td>\n",
    "        <b>optimization method</b>\n",
    "        </td>\n",
    "        <td>\n",
    "        <b>accuracy</b>\n",
    "        </td>\n",
    "    </tr>\n",
    "        <td>\n",
    "        Gradient descent\n",
    "        </td>\n",
    "        <td>\n",
    "        >94.6%\n",
    "        </td>\n",
    "    <tr>\n",
    "        <td>\n",
    "        Momentum\n",
    "        </td>\n",
    "        <td>\n",
    "        >95.6%\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "        Adam\n",
    "        </td>\n",
    "        <td>\n",
    "        94%\n",
    "        </td>\n",
    "    </tr>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¡Felicidades**! Has llegado al final del cuaderno de métodos de optimización. Aquí tienes un rápido resumen de todo lo que puedes hacer ahora: \n",
    "\n",
    "* Aplicar tres métodos de optimización diferentes a sus modelos \n",
    "* Construir minilotes para su conjunto de entrenamiento \n",
    "* Utilizar la programación de la tasa de aprendizaje para acelerar el entrenamiento\n",
    "\n",
    "¡Buen trabajo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
